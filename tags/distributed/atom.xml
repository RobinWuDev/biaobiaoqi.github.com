<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: distributed | Biaobiaoqi的博客]]></title>
  <link href="http://biaobiaoqi.github.com/tags/distributed/atom.xml" rel="self"/>
  <link href="http://biaobiaoqi.github.com/"/>
  <updated>2013-06-09T00:54:14+08:00</updated>
  <id>http://biaobiaoqi.github.com/</id>
  <author>
    <name><![CDATA[Biaobiaoqi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[SDN：软件定义网络]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/06/08/software-defined-network/"/>
    <updated>2013-06-08T00:39:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/06/08/software-defined-network</id>
    <content type="html"><![CDATA[<p>最近高级网络课的小组任务是在老师给定的范围内自选方向主题研究并做展示报告。我们组选了sdn。原以为这东西会是工业界无人问津的概念化产品，Google了一下却发现其实sdn挺火的，由于它可能带来的可扩展性，一些大互联网企业也在开始涉足相关的研发，比如Google呵Facebook。这里简要的梳理下我对SDN概念性的认识。</p>

<h2>背景</h2>

<h3>虚拟化的大趋势</h3>

<p>近年来，大数据、云计算兴起，虚拟化技术的重要性越发突出。提到虚拟化，不得不提的是计算机行业里的一句老话：</p>

<blockquote><p>计算机世界的绝大部分问题都可以通过分层的方法来解决</p></blockquote>

<p>其实虚拟化也可以理解成一种分层的思想。就拿云计算这个应用场景来说，虚拟化的技术就是在原有的<code>硬件-操作系统-用户</code>层次中，增添了<code>虚拟机</code>这么一层，变成了<code>硬件-虚拟机-操作系统-用户</code>，用虚拟机来管理硬件资源，增加了动态调整硬件资源的语义。</p>

<p>纵观计算机的发展历程，各方面都可以看到通过增加类似的虚拟化层次来提高生产效率的案例。比如高级语言之于汇编，比如图形界面之于命令行。这种添加层次的解决方案，总是能让问题得到更清晰的解决。</p>

<h3>网络虚拟化</h3>

<p>网络经历了<a href="http://article.yeeyan.org/view/100437/70880">数十年的发展</a>，如今在人们的生产、生活中发挥着巨大的作用。全球的网络拓扑结构结构错综复杂，有许多的自制系统组成。数据包从中国的一台PC机发出，访问到美国的主机，需经过一系列的路由、转发，而经由的网络拓扑节点由层层网关、路由器支配，难于控制。一些组织，在架设自身的可扩展、大规模网络环境时，也同样遇到了拓扑结构复杂、难于维护的问题。</p>

<p>如果能剥离开网络的物理拓扑结构，将网络资源虚拟化，隐藏物理结构的复杂性，统一的进行逻辑层的管理控制，就能满足多变的网络需求了。</p>

<p>SDN和OpenFlow就是一个这样的解决方案。</p>

<h2>OpenFlow和SDN</h2>

<p>OpenFlow起源于斯坦福的Ethane项目。该项目试图通过一个集中式的控制器，让网络管理员可以方便地定义基于网络流的安全控制策略，并将这些安全策略应用到各种网络设备中，从而实现对整个网络通讯的安全控制。受到此项目的启发，斯坦福的老师和学生将Ethane的设计更一般化，将传统网络设备的数据转发(data plane)和路由控制(control plane)两个功能模块相分离，通过集中式的控制器(Controller)以标准化的接口对各种网络设备进行管理和配置。2008年，他们提出了OpenFlow的概念。</p>

<p>这种分布式的实现方式，让控制平面可以和转发平面物理的分离开，控制平面完全可以运行在运算能力更强的服务器上，而不是路由器。OpenFlow协议则是分离的两者之间的通信协议。关于OpenFlow的技术细节，<a href="http://network.51cto.com/art/201306/397443.htm">《虚拟化的逆袭：OpenFlow和SDN》</a>一文中有简明介绍。</p>

<p>基于OpenFlow为网络带来的可编程的特性，有研究人员提出了SDN即Software Defined Network（2009年）。在这个概念中，网络中所有的网络设备被视为被管理的资源，以此抽象出一个网络操作系统(Network OS)的概念，这个网络操作系统一方面抽象了底层网络设备的具体细节，同时还为上层应用提供了统一的管理视图和编程接口。SDN的架构细节，参见<a href="http://network.51cto.com/art/201211/366278.htm">《SDN是生意 OpenFlow是技术》</a>。</p>

<p>SDN和OpenFlow的关系，就像互联网之于TCP/IP协议栈。OpenFlow是SDN的核心协议，用于控制转发面设备的控制转发。而SDN是上层的变成界面。</p>

<p>有观点认为，『OpenFlow是技术，SDN是生意』。最近对SDN唱衰的报道也证明了这桩『生意』的前途未仆。</p>

<h2>SDN的发展</h2>

<p>在云计算飞速发展的同时，SDN也喧嚣尘上。Google,Facebook等大公司也结成了产业联盟，来推动其发展。</p>

<p>但其现状也并非一片明朗：</p>

<blockquote><p>根据IDC的研究结果显示，在2013年，整个企业网络行业的市场价值为420亿美元，其中将近一半来自2-3层网络交换机市场。SDN只能产生约37亿美元的价值(8.8%)，而且要到2016年才能达到这个数字。与早前的预测相比，IDC的预测数字有所增加，但从整个网络行业来看，SDN仍然相去甚远。</p></blockquote>

<p>一方面，SDN的性能还有待改善，另一方面，由于SDN的统一平台的思想，会带来硬件设备的同质化，威胁到厂商的利益，将会面临来自厂商锁定的阻力。<a href="http://www.csdn.net/article/2013-06-08/2815714">《理性看待SDN》</a>一文中有较详细的解释。</p>

<p>虽然虚拟化能解放生产力，是大势所趋，但就像功耗更大的复杂指令集在市场上战胜了精简指令集一样，市场是残酷的。只能期待开源和开放的脚步不要停下。</p>

<h3>参考</h3>

<ul>
<li><a href="http://blog.sina.com.cn/s/blog_72628e9f0100yg3b.html">什么是SDN(Software Defined Networking)？</a>
*</li>
<li><a href="http://blog.sina.com.cn/s/blog_5385c0b901010pu3.html">OpenFlow/SDN本质论</a></li>
<li><a href="http://article.yeeyan.org/view/323168/358956">软件定义网络(SDN)：是什么，如何工作，为什么重要</a></li>
<li><a href="http://network.51cto.com/art/201305/394648.htm">SDN：仍处于起步阶段</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《Hadoop技术内幕》学习笔记——RPC和动态代理]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/06/08/ipc-in-hadoop/"/>
    <updated>2013-06-08T00:24:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/06/08/ipc-in-hadoop</id>
    <content type="html"><![CDATA[<p>本文是《hadoop技术内幕——深入解析Hadoop Common和HDFS架构设计与实现原理》第4章的1-3节的学习笔记。内容为Hadoop IPC部分的基础知识介绍。</p>

<h2>知识框架</h2>

<p>由于Hadoop分布式环境需要一个更高效和正对性优化的IPC机制，传统的诸如RMI的解决方案无法满足这一要求，Hadoop自己实现了一套IPC方法。</p>

<p>第4章第1节讲解了RPC的原理，包括Stub-Skeleton的架构等，进而用<code>RMI</code>举例（可以参考的<a href="">演示代码</a>）。RMI的调用实现主要包括了服务器端的registry和客户端的lookup。虽然Hadoop不是使用RMI做IPC，但了解一下其调用方式对感性的认识到如何进行分布式环境下的远程调用还是有作用的。</p>

<p>接下来的2,3小节，简单的介绍了IPC过程所依赖的技术方法：Java的动态代理方式和NIO的网络传输方式。</p>

<p>第2节讲<code>动态代理</code>，这里需要理解面向对象的代理模式和<em>动态</em>的原因。代理模式分很多种，这里用到的是简单的对行为的传递。动态代理的动态特性，则是因为框架能提供动态创建某个接口的实现的能力(可以参考的<a href="">演示代码</a>)。</p>

<p>更系统的看动态代理过程，分为两个阶段：</p>

<ul>
<li>1.代理接口的实现：静态方法Proxy.newInstance()生成动态对象。</li>
<li>2.调用转发过程：InvocationHandler实现</li>
</ul>


<p>第3节的<code>NIO</code>，跟传统的套接字(Socket)通信过程做了对比。需要了解Socket通信的特点：同步，阻塞，基于字节，理解这种特点带来的服务器端的线程闲置的压力。对应的，NIO则是可异步的，非阻塞的，基于块的。具体的实现上，需要了解缓冲区(Buffer)的原理和使用方式，通道(Channel)和选择器(Selector)配合的使用方式。</p>

<p>我总结了一份slides，如下：(挂在speackerdeck上，如果加载缓慢，请稍候:))</p>

<script async class="speakerdeck-embed" data-id="fbcb8590b1540130690c2e6f0be13e84" data-ratio="1.33333333333333" src="http://biaobiaoqi.github.com//speakerdeck.com/assets/embed.js"></script>


<p>slides下载地址：<a href="https://dl.dropboxusercontent.com/u/64021093/slides/%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8%E5%92%8CNIO.pdf">请戳</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[关于毕业季照片分享的思考]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/25/some-ideas-about-using-bt-protocol-to-sync/"/>
    <updated>2013-05-25T22:47:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/25/some-ideas-about-using-bt-protocol-to-sync</id>
    <content type="html"><![CDATA[<h2>背景</h2>

<p>毕业季到了，女朋友跟班里同学们一起拍了很多照片。由于照片分散在不同的人的手机、相机里，她也无法立即给我传来她的照片。这个情景一年前我也遇到过，只是当时自己比较忙，加上考虑着还会在本校读研，也没太在意毕业季照片的手机这一需求，以至于到现在我的电脑里甚至没有一张我穿学士服的照片:-=。而现在，当我想看看gf的照片时，这个需求横亘在我面前，让我特别的想解决掉它。</p>

<p>让我们从事实出发，理清问题的思路。</p>

<h2>需求的产生</h2>

<p>大学生拍毕业季照的现状：</p>

<ul>
<li>1.大学生在毕业季拍照留念是刚需，几乎平日爱拍照、不爱拍照的所有人都会参与其中。</li>
<li>2.拍照一般以小团体为基本单元进行。多是班级、社团这种常见的凝聚力较强的团体。</li>
<li>3.随着科技的发展和生活水平的提高，越来越多的人具备了拍出高质量照片的设备和实力。</li>
</ul>


<p>由于这种以小团体为单位的照片的大量产生，每个团体中的照片会交叉散落在较多人手中。在这种分散的格局面前，单独挑选出自己的照片并保存的成本巨大，直接导致了大家最终需求的统一：</p>

<ul>
<li>将所有的照片分发到所有人手中。</li>
</ul>


<h2>原有解决方案</h2>

<p>现有的解决方案主要方案归纳为如下四种：</p>

<ul>
<li><p>1.用移动硬盘等设备人力拷贝</p>

<p>  这种方式太过古老和原始，缺点费时费力。</p></li>
<li><p>2.使用公邮、网盘、QQ群共享等方式统一上传、下载</p>

<p>  主要缺点是外网网速限制；另外，网速的限制让用户上传和下载的门槛变高，影响了上传积极性，如果有人迟迟不上传，最终下载完整数据的时间也会一直拖延，带来消极的体验；如果注册一次性账号，这也不见得是环保的行为（或许这想法有点数据洁癖吧>&lt;），如果使用非一次性账号，那么权限管理将比较头疼。</p></li>
<li><p>3.使用内网BT资源站分别打包上传、下载</p>

<p>  优点是利用了内网网速的优势。缺点是每个人都打包做种，会让资源分散的很厉害，难于汇集。且做种等步骤对于部分用户而言，有操作门槛。</p></li>
<li><p>4.先使用1中方法，统一手机照片数据，然后按照2或3的方法发布数据</p>

<p>  这大概是最靠谱的方式了，缺点集中在需要有人费时费力的手机数据上。当然，如果班里有一个任劳任怨的好班长，这个问题就解决了。</p></li>
</ul>


<h4>总结：</h4>

<p>对于一个懒人而言，现有的解决方案都是蹩脚的。这些解决方案都不约而同的希望首先将数据聚合到一个外部空间中，然后再统一的分发给大家。这个步骤必要吗？实际上，我们只是需要每个人都方便、快捷的获得所有照片。</p>

<h2>一个简单的设计</h2>

<p>我将问题抽象为：</p>

<ul>
<li>完整的数据分散在10至20个数据拥有者手中，需要通过一定手段，让每个个体都不重复的拥有完整的数据。</li>
</ul>


<p>由于外网网速的限制，基于校园内网建立的工具就有了天然的优势。但如果使用内网，就不得不抛弃各大公司免费提供的邮箱存储空间、网盘存储空间。而校内的资源是有限的，没有自己的服务器，没有足够的空间存储大家的数据，这也就迫使我们考虑到了p2p的系统架构。于是，有了这样的解决方案，设定代号为BBT：</p>

<ul>
<li>PC机安装BBT工具软件后，可以设定<code>共享目录</code>和对应的<code>分享ID</code></li>
<li>放入特定<code>共享目录</code>的文件，将使用基于p2p同步的方式，在拥有相同的<code>分享ID</code>的<code>共享目录</code>间同步数据，目的是让所有人都获得到每个人的数据</li>
</ul>


<p>在跟阿豪童鞋的交流中，他建议为了进一步简化用户操作，可以尝试这样一种体验方式：</p>

<ul>
<li>班级内所有人在同一个链接下载工具软件。保证这一链接下载的软件能互相通信，实现数据同步。这杨就节省了用户自己设定相同的<code>分享ID</code>的流程，而将这一过程转移到班长请求下载链接的过程中。</li>
</ul>


<p>确实够简洁，很赞，实现成本还需要调研。</p>

<h6>BitTorrent Sync</h6>

<p>在构思的过程中，突然想起前几天在start up news上看到了一个基于BT协议的同步软件<a href="http://labs.bittorrent.com/experiments/sync.html">BitTorrent Sync</a>。</p>

<p><img src="http://labs.bittorrent.com/img/wide/sync.png" title="BitTorrent Sync" alt="BitTorrent Sync" /></p>

<p>它的实现方式大概是我们所需要的。可惜的是，由于它的功能全面，界面略显复杂。而同时，它并没有开放二次开发接口。</p>

<p>或许我需要自己搭建一个p2p的系统？</p>

<h6>PS:</h6>

<p>BT的优势，在于利用了所有节点的存储和传输能力，节点数量越多，下载越快</p>

<p>BitTorrent  Sync的优势，则在于能动态的集合分散在不同节点中的数据</p>

<p>感觉这种去中心化的分布式系统，前景大大的有啊;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop和RDBMS的混合系统介绍]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/20/hybrid-distributed-data-management-system/"/>
    <updated>2013-05-20T14:52:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/20/hybrid-distributed-data-management-system</id>
    <content type="html"><![CDATA[<p>现在大数据概念被时常提起，社会各界对其关注度越来越高。往往越是火热的东西，人们越容易忽略它的本质。在slides中，我首先按照自己的理解，简单的理顺数据处理领域的发展历程。之后，落脚点是两个比较有代表性的混合的分布式系统：<a href="http://biaobiaoqi.me/blog/2013/05/18/a-hybrid-system-hadoopdb/">HadoopDB</a>和微软的<a href="http://biaobiaoqi.me/blog/2013/04/25/split-querying-process-in-polybase/">Polybase</a>。由于缺乏实战经验，很多东西由各方论文和博文中得到，有不恰当的地方，欢迎大家拍砖讨论;)</p>

<p>slides的提纲如下：</p>

<!--more-->


<h2>提纲</h2>

<h3>背景</h3>

<ul>
<li>RDBMS的出现</li>
<li>大数据时代到来</li>
<li>NoSQL技术</li>
<li>新时代的挑战</li>
</ul>


<h3>HadoopDB</h3>

<ul>
<li>PB级数据分析</li>
<li>HadoopDB是什么</li>
<li>框架和组件介绍</li>
<li>示例</li>
<li>总结</li>
</ul>


<h3>Polybase</h3>

<ul>
<li>Polybase总览</li>
<li>PDW结构</li>
<li>Polybase的实现</li>
<li>性能分析</li>
</ul>


<p>slides在线展示：</p>

<script async class="speakerdeck-embed" data-id="77bdc950a3460130c98a12e3c5740641" data-ratio="1.33333333333333" src="http://biaobiaoqi.github.com//speakerdeck.com/assets/embed.js"></script>


<p>slides下载：
<a href="https://dl.dropboxusercontent.com/u/64021093/slides/Hybrid%20system.pdf">请戳这里</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分布式一致性]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/18/distributed-consistency/"/>
    <updated>2013-05-18T18:58:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/18/distributed-consistency</id>
    <content type="html"><![CDATA[<p>本文来自<a href="http://book.douban.com/subject/3108801/">《分布式原理与泛型》</a>的一致性章节笔记。由于缺乏实践经验，这本书对我来说太过理论，难于理解，现在已经暂停该书的阅读，转而加强实践。另有相关博文<a href="http://biaobiaoqi.me/blog/2013/05/15/cap-and-eventual-consistent/">《CAP和最终一致性》</a>，可供参考阅读。</p>

<!--more-->


<h3>1.分布式的一致性概述</h3>

<p>分布式系统的一个重要问题是数据的复制。对数据的复制一般有两个原因：</p>

<ul>
<li>1.增加系统的可靠性，防止单点失效的问题；</li>
<li>2.提高系统性能，利用不同地理位置的副本迅速响应用户需求。</li>
</ul>


<p>数据复制的主要难题是保持各个副本的一致性。即在更新一个副本时，必须确保同时更新其他的副本，否则数据的各个副本将不再相同。</p>

<h3>2.以数据为中心的一致性模型</h3>

<p>一致性模型实质上是进程和数据存储之间的一个约定。正常情况下，一个数据项上执行读操作时，它期待该操作返回的是该数据在其最后一次写操作之后的结果。在没有全局时钟的情况下，精确的定义哪次写操作是最后一次写操作是十分困难的。于是就产生了一系列用其他方式定义的一致性模型。</p>

<h4>2.1 持续一致性</h4>

<p>有人提定义了区分不一致性的三个互相独立的坐标轴：副本之间的数值偏差，副本之间新旧程度偏差以及更新操作顺序的偏差。</p>

<p>数值偏差可以这样理解：已应用于其他的副本，但还没有应用于给定副本的更新数目。</p>

<p>文中使用了<a href="http://en.wikipedia.org/wiki/Vector_clock">向量时钟</a>来举例对一致性单元进行持续抑制性分析，</p>

<h4>2.2 严格一致性</h4>

<p>任意read(x)操作都要读到最新的write(x)的结果。
依赖于绝对的全局时钟，实际系统不可能做到。</p>

<h4>2.3顺序一致性</h4>

<p>对于一些读写写操作的集合，所有进程看到的都是同样的顺序。也就是将并行的操作序列化，而且每个进程得到的序列都相同。</p>

<p>那么，很自然对于同一个进程执行的操作，必然要按照它们执行的顺序出现。</p>

<h4>2.4因果一致性（Casual Consitency）</h4>

<p>要求：</p>

<p>有因果关系的写操作必须按照它们的因果关系的顺序被看到，没有因果关系的写操作可以以任意顺序被别的进程看到。</p>

<p>例如：(其中[....]是占位符，表示没有操作)</p>

<blockquote><p>进程1  W(x)a 将x写成a
进程2  [..]R(x)a W(x)b
进程3  [....]R(x)a R(x)b
进程4  [....]R(x)b R(x)a</p></blockquote>

<p>进程3和1、2是满足因果一致性的，加上4就不满足了。因为进程2是由于读到x=a才把x写成b的，所以W(x)a和W(x)b之间有因果关系，必须按照因果的顺序出现。</p>

<p>相比顺序一致性，去掉了那些没有联系的操作达成一致顺序观点的要求，只是保留那些必要的顺序（有因果关系的）。</p>

<h4>2.5入口一致性（Entry Consistency）</h4>

<p>其实也就是对每个共享数据定义一个同步变量（即：锁）。当然，没有进行同步就进行的读操作结果是不保证的。</p>

<h3>3 客户为中心的一致性</h3>

<p>也就是从用户视角来看数据是一致的。只是关心数据最终会一致（eventually consitent）。</p>

<p>只要保证对于同一个用户，他访问到的数据是一致的就可以了。如果用户只是访问一个副本，这个就很好实现，否则就需要一定策略了。当没有更多的更新的时候，要保证当前的更新会最终传播到所有的副本上。著名的例子有：DNS系统，万维网。</p>

<p>但最终一致性需要注意一个典型的问题。即当客户访问不同的副本时，问题就出现了。更具体的例子比如，博客作者更改了一篇博文内容，在A地的用户先访问到最新的内容，而B地由于离博客服务器远，看到的还是原先的内容。</p>

<p>对于最终一致性的的数据存储而言，这个示例很有代表性。问题是由用户有时可能对不同的副本进行操作的事实引起的。以客户为中心的一致性分为如下几大类：</p>

<h4>3.1 单调读（Monotonic Reads）</h4>

<p>当进程从一个地方读出数据x，那么这个以后再读到的x应该是和当前x相同或比当前更新的版本。也就是如果进程迁移到了别的位置，那么对x的更新应该比进程先到达。这里的客户就是指这个进程。</p>

<h4>3.2 单调写（Monotonic Writes）</h4>

<p>跟单调读相应，如果一个进程写一个数据x，那么它在本地或者迁移到别的地方再进行写操作的时候，原来的写操作必须要先传播到这个位置。也就是进程要在任何地方至少和上一次写一样新的数据。</p>

<h4>3.3 Read your writes</h4>

<p>一个进程对于数据x的写操作，那么进程无论到任何副本上都应该看到这个写操作的影响，也就是看到和自己写操作的影响或者更新的值。</p>

<h4>3.4 Writes follow reads</h4>

<p>顾名思义了，也就是在读操作后面的写操作要是基于至少跟上一次读出来一样新的值。也就是如果进程在地点1读了x，那么在地点2要写x的副本的话，至少写的时候应该是基于至少和地点1读出的一样新的值。</p>

<h3>4 副本放置（Replica Placement）</h3>

<h4>4.1 放置的三个方法</h4>

<p>Permanent replica/永久副本: 选几个固定位置放置副本，镜像呈现。</p>

<p>Server-initiated/服务端发起: 服务端动态决定什么时候向什么地方分发副本，又称push cache</p>

<p>Client-initiated/客户端发起: 客户端缓存,client cache</p>

<h4>4.2 更新传播</h4>

<h5>4.2.1 传播什么？</h5>

<ul>
<li>可以是更新的通知（客户自己来取）</li>
<li>可以是更新后的数据</li>
<li>可以是更新的操作</li>
</ul>


<h5>4.2.2 谁来传播</h5>

<ul>
<li>服务器push或客户pull</li>
</ul>


<h5>4.2.3 传播协议？</h5>

<ul>
<li>保证最终会收敛到一致</li>
</ul>


<h4>4.3 复制协议（Replication Protocols）</h4>

<h5>4.3.1 远程写（Remote-Write）协议</h5>

<p>对于数据x有一个主副本，当没有x副本的服务器操作x的时候就会得到一个x的副本。而有x副本的服务器响应客户读请求的时候可以立刻返回。而当客户进行写操作的时候，写操作首先在主副本完成，然后再通知其他副本更新。</p>

<h5>4.3.2 本地写（Local-Write）协议</h5>

<p>和远程写比较类似，不同点是当一个服务器得到了副本以后就成了新的主副本，以后的写操作首先在本地完成，然后再通知其他的副本，本地写的名字由此而来。</p>

<h5>4.3.3 主动复制（Active Replication）</h5>

<p>对于副本的操作要设计到另外一个单一对象。比如，n个副本代理对象C的一个接口，如果向所有副本发出请求，每个副本都会发一个请求到C，那么同样的操作就执行了n次。所以需要一个协调者。另外，多副本返回值的时候也会有同样的情况。所以这种只执行一次的动作需要副本种有一个协调者，保证操作只被执行一次或者只返回一次。</p>

<h5>3.3.4 基于候选团（Quorum-Based）协议</h5>

<p>也就是读操作要得到r个服务器的同意，写操作要得到w个进程的同意。总共有n个进程。r和w要满足以下条件：</p>

<ul>
<li>r＋w > n 这样就不可能同时发生读写，并且读到的server肯定有一个以上被更新过的</li>
<li>w > n/2   这样就不可能同时发生两个写</li>
</ul>


<p>也就是类似于投票获得读写的锁。在Dynamo系统中可以配置这种wrn参数以自持特定的一致性。</p>
]]></content>
  </entry>
  
</feed>
