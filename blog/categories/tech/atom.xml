<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: tech | Biaobiaoqi的博客]]></title>
  <link href="http://biaobiaoqi.github.com/blog/categories/tech/atom.xml" rel="self"/>
  <link href="http://biaobiaoqi.github.com/"/>
  <updated>2013-05-17T01:39:15+08:00</updated>
  <id>http://biaobiaoqi.github.com/</id>
  <author>
    <name><![CDATA[Biaobiaoqi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[iOS的安全性和越狱]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/17/jail-break-your-ios/"/>
    <updated>2013-05-17T00:10:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/17/jail-break-your-ios</id>
    <content type="html"><![CDATA[<p><img src="https://dl.dropboxusercontent.com/u/64021093/2013-5-16.jpg" title="Jailbrek" alt="alt jailbreak" /></p>

<p>提到<a href="http://en.wikipedia.org/wiki/IOS_jailbreaking#Security.2C_privacy.2C_and_stability">越狱</a>，很多人第一反应大概是免费的游戏和app。</p>

<p>作为软件从业人员，深知中国的大环境的特殊性。内有用户想吃免费午餐的不良付费习惯，外有行业内大头诸如某讯对创新的绞杀。大家对越狱是为了免费、盗版软件的认识，也就不奇怪了。</p>

<p>还有另一派人。越狱对他们来说，意味着开放。个人认为这也是Hack精神的精髓之一。事实上，iOS越狱也有自己的生态圈：Cydia就是越狱设备上App Store。</p>

<!--more-->


<h2>越狱的合法性</h2>

<p>数字千年版权法对iphone的越狱进行了特赦，直到2015年，对iPhone、iPod touch的越狱依然有效。但注意，iPad就没这么幸运了。</p>

<p>详情参见博文<a href="http://www.cultofmac.com/213144/unlocking-a-new-iphone-is-now-illegal-but-jailbreaking-is-still-safe-what-it-all-means-for-you/">《Unlocking A New iPhone Is Now Illegal, But Jailbreaking Is Still Safe — What It All Means For You》</a></p>

<h2>iOS安全性</h2>

<p>由于iOS没有开源，学术界和工业界对它的安全机制的论述资料很少。我在网上找到了上交一位学长对ios安全机制的分析文章，是他的硕士学位<a href="http://www.doc88.com/p-405566264292.html">论文</a>。作为参考，我整理了一些关键知识点。</p>

<h4>基于信任链的启动</h4>

<p>iOS的信任机制从系统启动那一刻起已经开始。
系统可信启动<a href="http://elinux.org/images/2/28/Trusted_Boot_Loader.pdf">trustedboot</a>：启动每一步都会检测签名，构成整个信任链。</p>

<p>还有另一种启动方式，是设备固件升级方式（DFU，Device Firmware Update），也是由签名构建信任链。</p>

<h4>程序签名</h4>

<p>iOS应用的ipa压缩包中包含可执行文件和数据文件。可执行文件只有在已签名的前提下才能运行。确保应用经过苹果认证。</p>

<p>越狱提升运行权限到root，修改引用加载策略，接受任意签名的应用。
“通过软件保证软件安全是不可能的”，iOS使用了硬件来做保护，但硬件部分也遭到了越狱的破解。</p>

<h4>沙盒技术</h4>

<p>iOS用沙盒技术实现访问控制
trustedBSD ：http://www.trustedbsd.org/
http://www.freebsd.org/doc/zh_CN/books/arch-handbook/mac-synopsis.html</p>

<h4>ASLR和PIE</h4>

<p>使用地址空间布局随机化（ASLR， address space layout randomization）和位置无关可执行代码（PIE，position independent executable）编译用来防止经典的缓冲区溢出攻击。</p>

<h4>数据保护机制：</h4>

<ul>
<li>硬件加密：AES协处理器，存储着UID，GID</li>
<li>软件加密：系统中每个文件、数据都用一个唯一的秘钥来加密。秘钥是有UID、GID一起产生的，存在keybag中，keybag通过用户的4位密码来保护。</li>
</ul>


<h2>越狱</h2>

<p>越狱主要就是在信任链的根bootrom阶段攻击。由于系统不断升级，攻击的方式也在不断演进，这个<a href="http://bbs.gean.cn/archiver/showtopic-213.aspx">链接</a>介绍了其中的一种情况。</p>

<h4>越狱后注意</h4>

<p>总的来说，越狱打破了iOS封闭的生态环境，也打破了它特有的保护壳。手机获得了root权限，恶意代码有了可趁之机。不要轻易的使用来源不明的应用和插件。</p>

<ul>
<li>非越狱手机：仅允许用户访问照片、视频数据；通过备份，可在pc端获取所有数据</li>
<li>越狱手机：拥有root权限。可以通过许多渠道如ssh，ftp获取系统数据。</li>
</ul>


<p>更多细节参见
* <a href="http://bbs.weiphone.com/read-htm-tid-1750886.html">《浅谈iOS越狱前后的安全问题以及安全风险》</a>
* <a href="http://www.pcpop.com/doc/0/890/890768_all.shtml">《iPad越狱不安全!安装应用/插件需谨慎》</a>
* <a href="http://www.cnbeta.com/articles/229192.htm">《iOS完美越狱 - 福利还是阴谋？》</a></p>

<h4>SHSH</h4>

<p>iPhone 3GS出来时候，苹果为加强对iPhone OS的控制对恢复(Restore)固件(Firmware)采用了验证过程，每次iTunes要恢复固件的时候都要连接苹果的服务器验证。手机的ECID和所刷系统版本号一起签名出一个SHSH文件，发送给服务器，服务器检测SHSH是否为新版本的系统所产生，如果是，则允许继续进行刷机，否则传回组织继续的信号。</p>

<p>SHSH是存储在苹果公司的服务器上的，用户需要通过备份原来的SHSH，并伪装一台苹果服务器来协助验证。　　</p>

<p>网络上SHSH备份方法的介绍很多，不了解的朋友自行Google吧。</p>

<h2>附录</h2>

<p>对于想开发iOS应用而又没有开发者账号的朋友，可以参考这篇文章<a href="http://kqwd.blog.163.com/blog/static/4122344820117191351263/">《Xcode 4.1~4.6 + iOS 5、iOS 6免证书(iDP)开发+真机调试+生成IPA全攻略》</a>，Xcode4.6 iOS6.0 亲测有效。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CAP和最终一致性]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/15/cap-and-eventual-consistent/"/>
    <updated>2013-05-15T00:30:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/15/cap-and-eventual-consistent</id>
    <content type="html"><![CDATA[<p>查阅资料整理了最终一致性、CAP相关的内容。由于图省事儿，没有做文字的整理记载，只有slides和一些查阅过的链接，大家将就着看。欢迎指正。</p>

<p>slides：</p>

<script async class="speakerdeck-embed" data-id="cca07ce09e92013076c646310b996896" data-ratio="1.33333333333333" src="http://biaobiaoqi.github.com//speakerdeck.com/assets/embed.js"></script>




<!--more-->


<p>slides链接：<a href="https://speakerdeck.com/biaobiaoqi/cap-and-eventually-consistent">请戳这里</a></p>

<h2>背景</h2>

<p>为什么系统要扩张？历史的发展路径是怎么样的？请看<a href="http://rdc.taobao.com/blog/cs/?p=614">《系统可扩展性演化》</a></p>

<h2>CAP理论</h2>

<ul>
<li><p>CAP理论的提出：分布式系统的CAP理论是2000年左右被提出的概念，直到Dynamo的出现，开始在工业界被广泛实践：
<a href="http://www.julianbrowne.com/article/viewer/brewers-cap-theorem">《Brewer's CAP Theorem》</a>/<a href="http://code.alibabatech.com/blog/dev_related_728/brewers-cap-theorem.html">中文翻译</a></p></li>
<li><p>对CAP的理解：<a href="http://www.douban.com/group/topic/11765014/">《谈正确理解CAP理论》</a>\ <a href="http://rdc.taobao.com/blog/cs/?p=631">《CAP理论及分布式系统一致性》</a></p></li>
</ul>


<h2>BASE理论</h2>

<ul>
<li>BASE的理论解释：<a href="http://rdc.taobao.com/blog/cs/?p=637">《分布式事务工程实现》</a></li>
</ul>


<h2>最终一致性</h2>

<ul>
<li><p>amazon的CTO分析最终一致性：<a href="http://www.allthingsdistributed.com/2008/12/eventually_consistent.html">Eventually Consistent - Revisited</a>/<a href="http://blog.csdn.net/xiaoqiangxx/article/details/7566654">中文翻译</a></p></li>
<li><p>Dynamo论文：<a href="http://www.read.seas.harvard.edu/~kohler/class/cs239-w08/decandia07dynamo.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a></p>

<p>关于Dynamo的一篇中文简述：<a href="http://www.infoq.com/cn/articles/nosql-dynamo">《解读NoSQL技术代表之作Dynamo》</a></p></li>
</ul>


<h2>引申</h2>

<ul>
<li>CAP原作者对CAP的反思和澄清：<a href="http://www.infoq.com/cn/articles/cap-twelve-years-later-how-the-rules-have-changed">《CAP十二年回顾：规则变了》</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[全分布式的Hadoop初体验]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/12/touch-hadoop/"/>
    <updated>2013-05-12T00:26:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/12/touch-hadoop</id>
    <content type="html"><![CDATA[<h2>背景</h2>

<p>之前的时间里对Hadoop的使用都是基于学长所搭建起的实验环境的，没有完整的自己部署和维护过，最近抽时间初体验了在集群环境下装机、配置、运行的全过程，梳理总结到本文中。</p>

<h2>配置</h2>

<ul>
<li>内存:8G</li>
<li>CPU：i5-2400 3.1GHz；</li>
<li>硬盘：960G</li>
<li>系统：windows 7旗舰 64bits</li>
</ul>


<!--more-->


<ul>
<li>虚拟机：VMware7.1.1</li>
<li>虚拟集群：</li>
<li><ul>
<li>T （master节点）Ubuntu11.04 32 bits 内存512MB；硬盘100G；单核；</li>
</ul>
</li>
<li><ul>
<li>T2（slave节点） Ubuntu11.04 32 bits 内存512MB；硬盘100G；单核；</li>
</ul>
</li>
<li><ul>
<li>T3（slave节点） Ubuntu11.04 32 bits 内存512MB；硬盘100G；单核；</li>
</ul>
</li>
<li><ul>
<li>T4（slave节点） Ubuntu11.04 32 bits 内存512MB；硬盘100G；单核；</li>
</ul>
</li>
</ul>


<h2>环境准备</h2>

<h5>1.节点机器的配置</h5>

<p>配置固定IP:修改<code>/etc/nerwork/interfaces</code>
<code>
auto lo
iface lo inet loopback
address 192.168.108.131
gateway 192.168.108.2
netmask 192.168.108.0
broadcast 192.168.108.0
</code></p>

<p>为了便于管理，建议按统一约定修改hostname：修改<code>/etc/hostname</code>；同时，Hadoop集群要求每个节点使用同一个账号来管理、运行，所以，也需要设置好公用账号。</p>

<h5>2.集群ssh配置</h5>

<p>ssh相关原理和操作，参见博文<a href="http://biaobiaoqi.me/blog/2013/04/19/use-ssh/">《SSH原理和使用》</a>。</p>

<p>在每台机器上生成密钥对，并将所有机器的公钥集成到master的<code>~/.ssh/authorized_keys</code>中,之后将这个文件分发到集群所有机器上。
这样，所有机器之间都可以实现免密码的ssh访问了。</p>

<p>使用如下指令，可以将本机的公钥添加到master的authorized_keys文件末尾。当所有节点都执行一遍以后，再将master的authorized_keys发布到各个节点上。
```</p>

<h1>cat .ssh/id_rsa.pub | ssh T 'cat >> ~/.ssh/authorized_keys'</h1>

<p>```</p>

<h5>3.工具脚本</h5>

<p>在分布式的环境里，运维工作的自动化很有必要。为了方便集群的运维，我写了两个简单的batch脚本。</p>

<h6>统一执行脚本</h6>

<p>在所有节点上执行同样的动作。使用时，在master节点上调用batch脚本，参数为对应的batch执行语句。</p>

<p>```</p>

<h1>!/bin/bash</h1>

<h1>Program:</h1>

<h1>Execute instructions in hosts in slaveslist.</h1>

<h1>Description:</h1>

<h1>2013/5/8 biaobiaoqi First Release</h1>

<p>if [ $# -lt 1 ]; then
   echo  "usage: $0 COMMAND"
   exit 0
fi</p>

<p>for i in <code>cat slaveslist</code>
do
   ssh biaobiaoqi@$i "$1"
done</p>

<p>```</p>

<p>脚本中使用的slaveslist文件保存着所有slave节点的hostname，需要与脚本放在同一个工作目录下。</p>

<h6>统一替部署脚本</h6>

<p>将主节点的某文件或目录统一的更新部署替换到所有节点上（注意，所有节点拥有相同的目录结构，即替换的文件路径相同）。</p>

<p>遇到hadoop集群中节点的增删改动需要修改配置文件的，都可以通过这个脚本便捷的部署。</p>

<p>```</p>

<h1>!/bin/bash</h1>

<h1>Program:</h1>

<h1>Put the dirctory into all nodes of the cluster as the same path.</h1>

<h1>Description:</h1>

<h1>2013/5/10     biaobiaoqi     First Release</h1>

<p>if [ $# -lt 1 ]; then
   echo "Usage $0 DIR_PATH"
   exit 0
fi</p>

<p>for i in <code>cat slaveslist</code>
do
   ssh $i "rm ~/tmp -rf"
   scp -r $1 $i:~/tmp
   ssh $i "rm -rf $1;  mv ~/tmp $1"
done</p>

<p>```</p>

<h5>4.配置hosts文件</h5>

<p>由于hadoop体系在处理节点时，是使用的hostname，而非IP，所以必须先配置好hostname和IP的关系。
在一台机器上修改<code>/etc/hosts</code>
```</p>

<h1>/etc/hosts</h1>

<p>127.0.0.1     localhost
192.168.108.128     T3
192.168.108.129     T2
192.168.108.130 T
192.168.108.131 T4
```
然后使用统一执行脚本，将它发布到所有节点上。</p>

<p>值得注意的是，在<code>/etc/hostsname</code>中修改了host name之后，如果不同步的修改<code>/etc/hosts</code>中的相关信息，则在sudo操作时出现 <code>sudo: unable to resolve host</code>  的提示。原因是机器无法解析主机名。</p>

<p>修改<code>/etc/hosts</code>时也要特别注意，如果改成<code>127.0.0.1 localhost HOSTNAME</code> (其中HOSTNAME是主机名)的形式，在开启hadoop集群时，会出现datanode无法正常访问namenode，算是个小bug吧。所以得把hosts文件写成如上的形式。</p>

<h5>5.配置Java环境</h5>

<p>Hadoop需要Java1.6或更高版本，记住Java的安装目录，之后需要在hadoop配置过程中用到。</p>

<h2>安装Hadoop</h2>

<h5>1.下载Hadoop</h5>

<p>从官网下载<a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/">Hadoop发布版</a>（博主使用的是较早的稳定版0.20.2）</p>

<p>关于版本选择，推荐阅读：<a href="http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/">Hadoop版本选择探讨</a></p>

<h5>2.部署</h5>

<p>解压下载好的Hadoop，后放到合适的目录下。这里假定放置在/home/USER/ 的目录下</p>

<p>在<code>/home/USER/.bashrc</code>(其中USER为集群的用户名)文件中，增加如下语句，设定Hadoop相关的路径信息：
<code>
export JAVA_HOME=/usr/lib/jvm/java-6-openjdk
export HADOOP_HOME=/home/hadoop/Hadoop
export HADOOP_CONF=$HADOOP_HOME/conf
export HADOOP_PATH=$HADOOP_HOME/bin
export PATH=$HADOOP_PATH:$PATH
export CLASSPATH=.:$JAVA_HOME/bin:$PATH:$HADOOP_HOME:$HADOOP_HOME/bin
</code></p>

<h6>Hadoop核心配置修改</h6>

<p>配置文件在<code>$HADOOP_HOME/conf</code>目录下，其中基础配置比较重要的有三个：core-site.xml, hdfs-site.xml, mapred-site.xml。（当然，每个配置文件都有其细节作用，不过在初步实践hadoop时，理解这三个配置文件中的几个重要配置项就够了）</p>

<p>一般的，有三种可选模式。即本地模式、伪分布式模式和全分布式模式。前两种只是在单机环境下，后一种才是生产环境下的常用方式。《Hadoop权威指南》和《Hadoop实战》等书中都有讲到不同方式的配置，这里博主仅描述实验环境下4节点的全分布式配置。</p>

<p>core-site.xml整个hadoop的顶层配置
```
&lt;?xml version="1.0"?>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></p>

<!-- Put site-specific property overrides in this file. -->


<p><configuration></p>

<pre><code>&lt;property&gt;
     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
     &lt;value&gt;/home/biaobiaoqi/UDMS/hadoop-data/tmp-base&lt;/value&gt;
     &lt;description&gt;
    存放临时目录的路径，默认也被用来存储hdfs的元数据和文件数据，值得注意的是，hadoop账户对所设定的本地路径是否有足够的操作权限。之后再hdfs-site.xml中设定的dfs.data.dir和dfs.name.dir也要注意同样的问题
    &lt;/description&gt; 
&lt;/property&gt; 

 &lt;property&gt;   
      &lt;name&gt;fs.default.name&lt;/name&gt; 
      &lt;value&gt;hdfs://T:9000/&lt;/value&gt;
      &lt;description&gt;
    默认文件系统的标记。这个URI标记了文件系统的实现方式。UIR的协议决定了文件系统的实现类，而后面的值决定了文件系统的地址、端口等信息。
    &lt;/description&gt;
 &lt;/property&gt; 
</code></pre>

<p></configuration></p>

<p>```</p>

<p>hdfs-site.xml存储HDFS相关的信息</p>

<p>```
&lt;?xml version="1.0"?>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></p>

<!-- Put site-specific property overrides in this file. -->


<p><configuration></p>

<pre><code>&lt;property&gt;   
      &lt;name&gt;dfs.replication&lt;/name&gt;   
      &lt;value&gt;3&lt;/value&gt;   
      &lt;description&gt;默认的块的副本数量。实际的副本数量可以在文件写入的时候确定，默认的副本数则是在没有指定写入副本时被使用。 &lt;/description&gt; 
 &lt;/property&gt;
&lt;property&gt;
     &lt;name&gt;dfs.name.dir&lt;/name&gt;
      &lt;value&gt;/home/hadoop/hadoop-data/meta-data&lt;/value&gt;
    &lt;description&gt;
    设定hdfs的元数据信息存储地址。在namenode上。
    &lt;/description&gt;
 &lt;/property&gt;
 &lt;property&gt;
      &lt;name&gt;dfs.data.dir&lt;/name&gt;
      &lt;value&gt;/home/hadoop/hadoop-data/data&lt;/value&gt;
    &lt;description&gt;
    设定hdfs的数据存储地址。在datanode上。
    &lt;/description&gt;
 &lt;/property&gt;
</code></pre>

<p></configuration></p>

<p>```</p>

<p>mapred-site.xml存储mapreduce作业相关配置
```
&lt;?xml version="1.0"?>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></p>

<!-- Put site-specific property overrides in this file. -->


<p><configuration></p>

<pre><code>&lt;property&gt;   
      &lt;name&gt;mapred.job.tracker&lt;/name&gt;
      &lt;value&gt;T:9001&lt;/value&gt;   
      &lt;description&gt; Mapreduce 的job tracker所在的节点和端口。&lt;/description&gt; 
 &lt;/property&gt;
</code></pre>

<p></configuration></p>

<p>```</p>

<p>hosts文件存储了master节点</p>

<p><code>
T
</code></p>

<p>slaves文件存储着所有的slaves节点
<code>
T2
T3
T4
</code></p>

<h2>启动集群</h2>

<h5>1.格式化namenode</h5>

<p>如果是第一次起动集群，需要先格式化HDFS。</p>

<p>namenode存放了HDFS的元数据，故可以看成是对HDFS的格式化。</p>

<p><code>
$HADOOP_HOME/bin/hadoop namenode -format
</code></p>

<h5>2.启动守护进程</h5>

<p><code>
$HADOOP_HOME/bin/start-all.sh
</code>
等价于如下命令执行：
```</p>

<h1>start dfs daemons</h1>

<p>$"$bin"/start-dfs.sh --config $HADOOP_CONF_DIR</p>

<h1>start mapred daemons</h1>

<p>$"$bin"/start-mapred.sh --config $HADOOP_CONF_DIR</p>

<p>```
如果成功，打开 http://T:50070 (T为集群master节点)，可以看到HDFS的运行情况，包括节点数量、空间大小等。这是Hadoop自带的HDFS监控页面；同样的，http://T:50030 是Mapreduce的监控界面。</p>

<p>如果没有成功，根据$HADOOP_HOME/logs目录下的日志文件信息debug。</p>

<h5>3.常见问题</h5>

<ul>
<li>namenode无法启动：</li>
<li><ul>
<li>删除掉本地文件系统中HDFS的目录文件，重新格式化HDFS。</li>
</ul>
</li>
<li><ul>
<li>HDFS目录的权限不够，更改权限设置等。</li>
</ul>
</li>
<li>namenode启动成功，datanode无法连接：检查hosts文件是否设置正确；检查各个配置文件中地址值是否使用了IP而不是hostname。</li>
<li>namenode启动成功，datanode无法启动：Incompatible namespaceIDs，由于频繁格式化，造成dfs.name.dir/current/VERSION与dfs.data.dir/current/VERSION数据不一致。</li>
<li>SafeModeException： 分布式系统启动时，会进入安全模式，安全模式下，hadoop是无法执行的。一般的等待一会儿，就可以正常使用了。如果是由于之前集群崩溃造成的无法自动退出安全模式的情况，则需要如下特殊处理了
<code>
$/$HADOOP_HOME/bin/hadoop dfsadmin -safemode leave
</code></li>
</ul>


<h2>初体验</h2>

<p>最简单的尝试就是使用Hadoop自带的wordcount程序了，参照<a href="http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504205.html">这篇文章</a>，描述很详细。</p>

<p>其他的一些尝试： <a href="http://www.cnblogs.com/rilley/archive/2012/02/13/2349858.html">动态增删节点</a> 、 <a href="http://www.cnblogs.com/ggjucheng/archive/2012/04/18/2454696.html">修改备份数量</a></p>

<h2>参考</h2>

<p><a href="http://hadoop.apache.org/docs/stable/cluster_setup.html">offical document: Cluster Setup</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[虚拟机中的网络配置]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/09/networking-in-virtual-machine/"/>
    <updated>2013-05-09T22:39:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/09/networking-in-virtual-machine</id>
    <content type="html"><![CDATA[<p>本文介绍三种虚拟机中常用的网络配置模式：NAT(网络地址转换模式)、Bridged nerworking（桥接网络模式）和Host-only（主机模式）。</p>

<h3>Network Address Translation (NAT)</h3>

<p>NAT模式使用了<a href="http://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2">NAT</a>服务来给虚拟网络提供网络连接。</p>

<p>这种模式下，虚拟机能访问外部网络，外部无法直接连接到内部网络，除非使用端口映射<a href="http://nxlhero.blog.51cto.com/962631/742140">port forwarding</a>。</p>

<!--more-->


<p>NAT一般与<a href="http://zh.wikipedia.org/wiki/DHCP">DHCP</a>一起使用，以动态分配虚拟机内网IP，无序手动配置内外部网络环境。当然，为了让虚拟机每次开机时拥有固定的IP，也可以关闭掉DHCP服务，转而自己配置虚拟机的网络。虚拟机是linux的情况下，可以通过修改/etc/network/interfaces实现开机固定IP，示例如下：</p>

<p>```</p>

<h1>This file describes the network interfaces available on your system</h1>

<h1>and how to activate them. For more information, see interfaces(5).</h1>

<h1>The loopback network interface</h1>

<p>auto lo
iface lo inet loopback</p>

<p>auto eth0
iface eth0 inet static
address 172.21.2.43
netmask 255.255.0.0
gateway 172.21.1.1</p>

<p>```</p>

<p>实现原理如图：</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/network/2.jpg"></p>

<h3>Bridged networking(桥接)</h3>

<p>在桥接模式下，本地物理网卡和虚拟网卡通过虚拟交换机进行桥接（无需在host上再开启新的虚拟网卡），物理网卡和虚拟网卡在拓扑图上处于同等地位，虚拟机就像是一台真实主机一样存在于局域网中。</p>

<p>桥接模式无法与DHCP一起使用，需要手动的配置虚拟机的网络参数，包括IP、网关、子网掩码和dns。其中网关、子网掩码、dns都应该与host设置相同值。在linux虚拟机中的设置示例如下：</p>

<p>```</p>

<h1>设置ip、子网掩码</h1>

<p>$ifconfig eth0 172.21.2.43 netmask 255.255.0.0</p>

<h1>设置默认网关</h1>

<p>$route add default gw 172.21.1.1</p>

<h1>设置dns</h1>

<p>$sudo vim /etc/resolv.conf
nameserver 172.21.1.1</p>

<p>```</p>

<p>实现原理如图：</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/network/1.jpg"></p>

<p>相比NAT，桥接模式有一个前提条件，就是要获得另外一个host所在网段的IP。在内网环境中还很容易，如果是ADSL宽带就比较麻烦了，ISP一般是不会大方的多提供一个公网IP的，那种情况下，使用NAT或许是更好的选择。</p>

<p><a href="http://blog.chinaunix.net/uid-26212859-id-3051291.html">VMware的桥接网络配置</a></p>

<h3>Host-only networking(主机)</h3>

<p>以host为网关建立了新的虚拟网络，虚拟机无法访问外部网络，因此很安全。</p>

<p>和NAT一样，也使用了DHCP服务做虚拟网络内的IP自动分配。</p>

<p>另外，host-only模式下也可以进行扩展配置，让虚拟网络的机器也能访问到外网，比如自定制nat和dhcp的使用等等。</p>

<p>如图：</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/network/3.jpg"></p>

<h2>参考资料</h2>

<ul>
<li><p><a href="http://networking.ctocio.com.cn/tips/110/8897610.shtml">解析虚拟VMware三种网络模式根本区别</a></p></li>
<li><p><a href="http://www.virtualbox.org/manual/ch06.html">virtualbox的网络模式详解</a></p></li>
</ul>


<p>图片引用自 ：<a href="http://networking.ctocio.com.cn/tips/110/8897610.shtml">解析虚拟VMware三种网络模式根本区别</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[根据前中后序和层序重建二叉树(PAT1020、PAT1043)]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/04/27/pat1020-pat1043-rebuild-binary-tree/"/>
    <updated>2013-04-27T22:33:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/04/27/pat1020-pat1043-rebuild-binary-tree</id>
    <content type="html"><![CDATA[<h2>背景</h2>

<p><a href="/blog/2013/04/27/travsal-binary-tree/">《二叉树的遍历（递归、非递归）分析》</a>总结了二叉树不同遍历方式的递归和非递归实现，本文则讨论如何针对不同遍历方式的组合重建二叉树。为了简化问题的考虑，假定二叉树中不会出现重复值。列入考虑范围的有前序、中序、后序、层序遍历这四种的组合。前中后序比较常见，而层序则相对特殊一点了。</p>

<p><a href="http://pat.zju.edu.cn/contests/pat-a-practise">PAT</a>的1043和1020题是遍历相关的模板题，正好派上用场。</p>

<!--more-->


<h2>中序+前序</h2>

<h5>算法描述：</h5>

<ul>
<li><p>初始：用前序遍历序列确定根节点，在中序遍历序列中找到该根节点，则左右子树分别为中序中该节点左右的序列。</p></li>
<li><p>迭代：对各个子树分别执行三步操作，1.在前序序列中找子树的根节点；2。在中序序列中找子树的根节点，并划分开根节点的左右子树；3.根据新生成的左右子树，在前序序列中划分开这些节点，从而得到了两颗子树的前序、中序序列。</p></li>
</ul>


<h5>练习：<a href="http://pat.zju.edu.cn/contests/pat-a-practise/1043">PAT1043:Is It a Binary Search Tree</a></h5>

<h5>题意：</h5>

<p>输入一个树的前序遍历序列，判定这个树是否是二叉搜索树或者BST的镜像树，如果是，则用后序序列输出。</p>

<h5>解题思路：</h5>

<ul>
<li><p>1.BST很特殊，实质上BST的所有节点的顺序排列就是中序遍历了。</p></li>
<li><p>2.要检查树是否是BST或者镜像BST，只需按照重建树的思路，在每次重建的过程中做适当检查即可。检查思路是：检查前序遍历序列中，根节点之后的节点排序是否符合BST的二分规则（即前一段都是小于根节点的，后一段都是大于根节点的）。</p></li>
<li><p>3.最后的输出是后序遍历。过程中其实并不用构建整个树，直接在处理过程中，按后序的方式存储节点到队列中即可。</p></li>
</ul>


<p>有了这些考虑，就可以写出代码啦。详细解题代码见链接<a href="https://github.com/biaobiaoqi/biaobiaoqiCode/blob/master/src/biaobiaoqi/pat/advancedlevel/APAT1043.java">PAT1043</a></p>

<h2>中序+后序</h2>

<h5>算法描述：</h5>

<ul>
<li><p>初始：用后序遍历序列确定根节点，在中序遍历序列中找到该根节点，则左右子树分别为中序中该节点左右的序列。</p></li>
<li><p>迭代：对各个子树分别执行三步操作，1.在后序序列中找子树的根节点；2。在中序序列中找子树的根节点，并划分开根节点的左右子树；3.根据新生成的左右子树，在后序序列中划分开这些节点，从而得到了两颗子树的后序、中序序列。</p></li>
</ul>


<h5>练习：<a href="http://pat.zju.edu.cn/contests/pat-a-practise/1020">PAT1020:Tree Traversals</a></h5>

<h5>题意：</h5>

<p>输入为一棵二叉树的后序遍历序列和中序遍历序列。求树的前序遍历序列。</p>

<h5>解题思路：</h5>

<ul>
<li><p>1.有了中序和后序，就能重建树。</p></li>
<li><p>2.最后的输出是前序遍历。过程中其实并不用构建整个树。直接在处理过程中，按前序的方式存储节点到队列中即可。</p></li>
</ul>


<p>详细解题代码见链接<a href="https://github.com/biaobiaoqi/biaobiaoqiCode/blob/master/src/biaobiaoqi/pat/advancedlevel/APAT1020.java">PAT1020</a></p>

<h2>中序+层序</h2>

<h5>算法描述：</h5>

<ul>
<li><p>初始：用层序遍历确定顶节点，在中序遍历中，利用顶节点划分出左右子树。</p></li>
<li><p>迭代：对各个子树分别执行三步操作，1.在层序序列中，找出子树节点集合中，最靠前的节点，这个节点即为子树的顶节点；2.在中序序列中找1中得到的顶节点，并划分开顶节点的左右子树；</p></li>
<li><p>跟（中序+前序）和（中序+后序）不同之处在于没有迭代的第3步，层序是无法直接划分得到左右子树的节点集合的。但这并不妨碍正常的处理。层序是用来找到子树的顶节点的，而顶节点即是所有子树的节点中，在层序遍历中最靠前的节点。</p></li>
</ul>


<h2><del>前序+后序</del></h2>

<p>这个组合是<strong>无法</strong>重建确定的二叉树的。</p>

<p>对于满二叉树，利用子树节点的排列顺序能区分开左右子树节点集合，构建是没有问题的。但一旦有单个叶子的节点存在，则无法确定叶子是左儿子还是右儿子。因为无论是前序还是后序序列，都无法体现单个儿子情况下，儿子的位置。前序会将左右子树的点置于节点之后，后序则是将左右子树的点置于节点之前。</p>

<ul>
<li>举个简单的反例：</li>
</ul>


<blockquote><p>给出如下的前序序列和后序序列：
preorder: A, B;
postorder: B, A</p>

<p>能构建的二叉树有两种可能，1.A是根节点，B是A左儿子； 2.A是根节点， B是A的右儿子。无法得到一个唯一的结果。</p></blockquote>

<h2><del>前序+层序</del></h2>

<p>这个组合也是无法重建确定的二叉树的。同样于后序+层序的情况。</p>

<p>道理跟（前序+后序）的道理一样，无论是前序、后序，还是层序，都是无法确定单个儿子节点情况下儿子节点的顺序。</p>

<h2>总结</h2>

<ul>
<li>中序遍历配合另外任何一个遍历，能重建二叉树。其他的任意两个序列的组合都不能唯一的确定重建的二叉树。</li>
</ul>

]]></content>
  </entry>
  
</feed>
