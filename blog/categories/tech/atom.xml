<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: tech | Biaobiaoqi的博客]]></title>
  <link href="http://biaobiaoqi.github.com/blog/categories/tech/atom.xml" rel="self"/>
  <link href="http://biaobiaoqi.github.com/"/>
  <updated>2013-05-12T00:37:00+08:00</updated>
  <id>http://biaobiaoqi.github.com/</id>
  <author>
    <name><![CDATA[Biaobiaoqi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[全分布式的Hadoop初体验]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/12/touch-hadoop/"/>
    <updated>2013-05-12T00:26:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/12/touch-hadoop</id>
    <content type="html"><![CDATA[<h2>背景</h2>

<p>之前的时间里对Hadoop的使用都是基于学长所搭建起的实验环境的，没有完整的自己部署和维护过，最近抽时间初体验了在集群环境下装机、配置、运行的全过程，梳理总结到本文中。</p>

<h2>配置</h2>

<ul>
<li>内存:8G</li>
<li>CPU：i5-2400 3.1GHz；</li>
<li>硬盘：960G</li>
<li>系统：windows 7旗舰 64bits</li>
</ul>


<!--more-->


<ul>
<li>虚拟机：VMware7.1.1</li>
<li>虚拟集群：</li>
<li><ul>
<li>T （master节点）Ubuntu11.04 32 bits 内存512MB；硬盘100G；单核；</li>
</ul>
</li>
<li><ul>
<li>T2（slave节点） Ubuntu11.04 32 bits 内存512MB；硬盘100G；单核；</li>
</ul>
</li>
<li><ul>
<li>T3（slave节点） Ubuntu11.04 32 bits 内存512MB；硬盘100G；单核；</li>
</ul>
</li>
<li><ul>
<li>T4（slave节点） Ubuntu11.04 32 bits 内存512MB；硬盘100G；单核；</li>
</ul>
</li>
</ul>


<h2>环境准备</h2>

<h5>1.节点机器的配置</h5>

<p>配置固定IP:修改<code>/etc/nerwork/interfaces</code>
<code>
auto lo
iface lo inet loopback
address 192.168.108.131
gateway 192.168.108.2
netmask 192.168.108.0
broadcast 192.168.108.0
</code></p>

<p>为了便于管理，建议按统一约定修改hostname：修改<code>/etc/hostname</code>；同时，Hadoop集群要求每个节点使用同一个账号来管理、运行，所以，也需要设置好公用账号。</p>

<h5>2.集群ssh配置</h5>

<p>ssh相关原理和操作，参见博文<a href="http://biaobiaoqi.me/blog/2013/04/19/use-ssh/">《SSH原理和使用》</a>。</p>

<p>在每台机器上生成密钥对，并将所有机器的公钥集成到master的<code>~/.ssh/authorized_keys</code>中,之后将这个文件分发到集群所有机器上。
这样，所有机器之间都可以实现免密码的ssh访问了。</p>

<p>使用如下指令，可以将本机的公钥添加到master的authorized_keys文件末尾。当所有节点都执行一遍以后，再将master的authorized_keys发布到各个节点上。
```</p>

<h1>cat .ssh/id_rsa.pub | ssh T 'cat >> ~/.ssh/authorized_keys'</h1>

<p>```</p>

<h5>3.工具脚本</h5>

<p>在分布式的环境里，运维工作的自动化很有必要。为了方便集群的运维，我写了两个简单的batch脚本。</p>

<h6>统一执行脚本</h6>

<p>在所有节点上执行同样的动作。使用时，在master节点上调用batch脚本，参数为对应的batch执行语句。</p>

<p>```</p>

<h1>!/bin/bash</h1>

<h1>Program:</h1>

<h1>Execute instructions in hosts in slaveslist.</h1>

<h1>Description:</h1>

<h1>2013/5/8 biaobiaoqi First Release</h1>

<p>if [ $# -lt 1 ]; then
   echo  "usage: $0 COMMAND"
   exit 0
fi</p>

<p>for i in <code>cat slaveslist</code>
do
   ssh biaobiaoqi@$i "$1"
done</p>

<p>```</p>

<p>脚本中使用的slaveslist文件保存着所有slave节点的hostname，需要与脚本放在同一个工作目录下。</p>

<h6>统一替部署脚本</h6>

<p>将主节点的某文件或目录统一的更新部署替换到所有节点上（注意，所有节点拥有相同的目录结构，即替换的文件路径相同）。</p>

<p>遇到hadoop集群中节点的增删改动需要修改配置文件的，都可以通过这个脚本便捷的部署。</p>

<p>```</p>

<h1>!/bin/bash</h1>

<h1>Program:</h1>

<h1>Put the dirctory into all nodes of the cluster as the same path.</h1>

<h1>Description:</h1>

<h1>2013/5/10     biaobiaoqi     First Release</h1>

<p>if [ $# -lt 1 ]; then
   echo "Usage $0 DIR_PATH"
   exit 0
fi</p>

<p>for i in <code>cat slaveslist</code>
do
   ssh $i "rm ~/tmp -rf"
   scp -r $1 $i:~/tmp
   ssh $i "rm -rf $1;  mv ~/tmp $1"
done</p>

<p>```</p>

<h5>4.配置hosts文件</h5>

<p>由于hadoop体系在处理节点时，是使用的hostname，而非IP，所以必须先配置好hostname和IP的关系。
在一台机器上修改<code>/etc/hosts</code>
```</p>

<h1>/etc/hosts</h1>

<p>127.0.0.1     localhost
192.168.108.128     T3
192.168.108.129     T2
192.168.108.130 T
192.168.108.131 T4
```
然后使用统一执行脚本，将它发布到所有节点上。</p>

<p>值得注意的是，在<code>/etc/hostsname</code>中修改了host name之后，如果不同步的修改<code>/etc/hosts</code>中的相关信息，则在sudo操作时出现 <code>sudo: unable to resolve host</code>  的提示。原因是机器无法解析主机名。</p>

<p>修改<code>/etc/hosts</code>时也要特别注意，如果改成<code>127.0.0.1 localhost HOSTNAME</code> (其中HOSTNAME是主机名)的形式，在开启hadoop集群时，会出现datanode无法正常访问namenode，算是个小bug吧。所以得把hosts文件写成如上的形式。</p>

<h5>5.配置Java环境</h5>

<p>Hadoop需要Java1.6或更高版本，记住Java的安装目录，之后需要在hadoop配置过程中用到。</p>

<h2>安装Hadoop</h2>

<h5>1.下载Hadoop</h5>

<p>从官网下载<a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/">Hadoop发布版</a>（博主使用的是较早的稳定版0.20.2）</p>

<p>关于版本选择，推荐阅读：<a href="http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/">Hadoop版本选择探讨</a></p>

<h5>2.部署</h5>

<p>解压下载好的Hadoop，后放到合适的目录下。这里假定放置在/home/USER/ 的目录下</p>

<p>在<code>/home/USER/.bashrc</code>(其中USER为集群的用户名)文件中，增加如下语句，设定Hadoop相关的路径信息：
<code>
export JAVA_HOME=/usr/lib/jvm/java-6-openjdk
export HADOOP_HOME=/home/hadoop/Hadoop
export HADOOP_CONF=$HADOOP_HOME/conf
export HADOOP_PATH=$HADOOP_HOME/bin
export PATH=$HADOOP_PATH:$PATH
export CLASSPATH=.:$JAVA_HOME/bin:$PATH:$HADOOP_HOME:$HADOOP_HOME/bin
</code></p>

<h6>Hadoop核心配置修改</h6>

<p>配置文件在<code>$HADOOP_HOME/conf</code>目录下，其中基础配置比较重要的有三个：core-site.xml, hdfs-site.xml, mapred-site.xml。（当然，每个配置文件都有其细节作用，不过在初步实践hadoop时，理解这三个配置文件中的几个重要配置项就够了）</p>

<p>一般的，有三种可选模式。即本地模式、伪分布式模式和全分布式模式。前两种只是在单机环境下，后一种才是生产环境下的常用方式。《Hadoop权威指南》和《Hadoop实战》等书中都有讲到不同方式的配置，这里博主仅描述实验环境下4节点的全分布式配置。</p>

<p>core-site.xml整个hadoop的顶层配置
```
&lt;?xml version="1.0"?>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></p>

<!-- Put site-specific property overrides in this file. -->


<p><configuration></p>

<pre><code>&lt;property&gt;
     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
     &lt;value&gt;/home/biaobiaoqi/UDMS/hadoop-data/tmp-base&lt;/value&gt;
     &lt;description&gt;
    存放临时目录的路径，默认也被用来存储hdfs的元数据和文件数据，值得注意的是，hadoop账户对所设定的本地路径是否有足够的操作权限。之后再hdfs-site.xml中设定的dfs.data.dir和dfs.name.dir也要注意同样的问题
    &lt;/description&gt; 
&lt;/property&gt; 

 &lt;property&gt;   
      &lt;name&gt;fs.default.name&lt;/name&gt; 
      &lt;value&gt;hdfs://T:9000/&lt;/value&gt;
      &lt;description&gt;
    默认文件系统的标记。这个URI标记了文件系统的实现方式。UIR的协议决定了文件系统的实现类，而后面的值决定了文件系统的地址、端口等信息。
    &lt;/description&gt;
 &lt;/property&gt; 
</code></pre>

<p></configuration></p>

<p>```</p>

<p>hdfs-site.xml存储HDFS相关的信息</p>

<p>```
&lt;?xml version="1.0"?>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></p>

<!-- Put site-specific property overrides in this file. -->


<p><configuration></p>

<pre><code>&lt;property&gt;   
      &lt;name&gt;dfs.replication&lt;/name&gt;   
      &lt;value&gt;3&lt;/value&gt;   
      &lt;description&gt;默认的块的副本数量。实际的副本数量可以在文件写入的时候确定，默认的副本数则是在没有指定写入副本时被使用。 &lt;/description&gt; 
 &lt;/property&gt;
&lt;property&gt;
     &lt;name&gt;dfs.name.dir&lt;/name&gt;
      &lt;value&gt;/home/hadoop/hadoop-data/meta-data&lt;/value&gt;
    &lt;description&gt;
    设定hdfs的元数据信息存储地址。在namenode上。
    &lt;/description&gt;
 &lt;/property&gt;
 &lt;property&gt;
      &lt;name&gt;dfs.data.dir&lt;/name&gt;
      &lt;value&gt;/home/hadoop/hadoop-data/data&lt;/value&gt;
    &lt;description&gt;
    设定hdfs的数据存储地址。在datanode上。
    &lt;/description&gt;
 &lt;/property&gt;
</code></pre>

<p></configuration></p>

<p>```</p>

<p>mapred-site.xml存储mapreduce作业相关配置
```
&lt;?xml version="1.0"?>
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></p>

<!-- Put site-specific property overrides in this file. -->


<p><configuration></p>

<pre><code>&lt;property&gt;   
      &lt;name&gt;mapred.job.tracker&lt;/name&gt;
      &lt;value&gt;T:9001&lt;/value&gt;   
      &lt;description&gt; Mapreduce 的job tracker所在的节点和端口。&lt;/description&gt; 
 &lt;/property&gt;
</code></pre>

<p></configuration></p>

<p>```</p>

<p>hosts文件存储了master节点</p>

<p><code>
T
</code></p>

<p>slaves文件存储着所有的slaves节点
<code>
T2
T3
T4
</code></p>

<h2>启动集群</h2>

<h5>1.格式化namenode</h5>

<p>如果是第一次起动集群，需要先格式化HDFS。</p>

<p>namenode存放了HDFS的元数据，故可以看成是对HDFS的格式化。</p>

<p><code>
$HADOOP_HOME/bin/hadoop namenode -format
</code></p>

<h5>2.启动守护进程</h5>

<p><code>
$HADOOP_HOME/bin/start-all.sh
</code>
等价于如下命令执行：
```</p>

<h1>start dfs daemons</h1>

<p>$"$bin"/start-dfs.sh --config $HADOOP_CONF_DIR</p>

<h1>start mapred daemons</h1>

<p>$"$bin"/start-mapred.sh --config $HADOOP_CONF_DIR</p>

<p>```
如果成功，打开 http://T:50070 (T为集群master节点)，可以看到HDFS的运行情况，包括节点数量、空间大小等。这是Hadoop自带的HDFS监控页面；同样的，http://T:50030 是Mapreduce的监控界面。</p>

<p>如果没有成功，根据$HADOOP_HOME/logs目录下的日志文件信息debug。</p>

<h5>3.常见问题</h5>

<ul>
<li>namenode无法启动：</li>
<li><ul>
<li>删除掉本地文件系统中HDFS的目录文件，重新格式化HDFS。</li>
</ul>
</li>
<li><ul>
<li>HDFS目录的权限不够，更改权限设置等。</li>
</ul>
</li>
<li>namenode启动成功，datanode无法连接：检查hosts文件是否设置正确；检查各个配置文件中地址值是否使用了IP而不是hostname。</li>
<li>namenode启动成功，datanode无法启动：Incompatible namespaceIDs，由于频繁格式化，造成dfs.name.dir/current/VERSION与dfs.data.dir/current/VERSION数据不一致。</li>
<li>SafeModeException： 分布式系统启动时，会进入安全模式，安全模式下，hadoop是无法执行的。一般的等待一会儿，就可以正常使用了。如果是由于之前集群崩溃造成的无法自动退出安全模式的情况，则需要如下特殊处理了
<code>
$/$HADOOP_HOME/bin/hadoop dfsadmin -safemode leave
</code></li>
</ul>


<h2>初体验</h2>

<p>最简单的尝试就是使用Hadoop自带的wordcount程序了，参照<a href="http://www.cnblogs.com/xia520pi/archive/2012/05/16/2504205.html">这篇文章</a>，描述很详细。</p>

<p>其他的一些尝试： <a href="http://www.cnblogs.com/rilley/archive/2012/02/13/2349858.html">动态增删节点</a> 、 <a href="http://www.cnblogs.com/ggjucheng/archive/2012/04/18/2454696.html">修改备份数量</a></p>

<h2>参考</h2>

<p><a href="http://hadoop.apache.org/docs/stable/cluster_setup.html">offical document: Cluster Setup</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[虚拟机中的网络配置]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/05/09/networking-in-virtual-machine/"/>
    <updated>2013-05-09T22:39:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/05/09/networking-in-virtual-machine</id>
    <content type="html"><![CDATA[<p>本文介绍三种虚拟机中常用的网络配置模式：NAT(网络地址转换模式)、Bridged nerworking（桥接网络模式）和Host-only（主机模式）。</p>

<h3>Network Address Translation (NAT)</h3>

<p>NAT模式使用了<a href="http://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2">NAT</a>服务来给虚拟网络提供网络连接。</p>

<p>这种模式下，虚拟机能访问外部网络，外部无法直接连接到内部网络，除非使用端口映射<a href="http://nxlhero.blog.51cto.com/962631/742140">port forwarding</a>。</p>

<!--more-->


<p>NAT一般与<a href="http://zh.wikipedia.org/wiki/DHCP">DHCP</a>一起使用，以动态分配虚拟机内网IP，无序手动配置内外部网络环境。当然，为了让虚拟机每次开机时拥有固定的IP，也可以关闭掉DHCP服务，转而自己配置虚拟机的网络。虚拟机是linux的情况下，可以通过修改/etc/network/interfaces实现开机固定IP，示例如下：</p>

<p>```</p>

<h1>This file describes the network interfaces available on your system</h1>

<h1>and how to activate them. For more information, see interfaces(5).</h1>

<h1>The loopback network interface</h1>

<p>auto lo
iface lo inet loopback</p>

<p>auto eth0
iface eth0 inet static
address 172.21.2.43
netmask 255.255.0.0
gateway 172.21.1.1</p>

<p>```</p>

<p>实现原理如图：</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/network/2.jpg"></p>

<h3>Bridged networking(桥接)</h3>

<p>在桥接模式下，本地物理网卡和虚拟网卡通过虚拟交换机进行桥接（无需在host上再开启新的虚拟网卡），物理网卡和虚拟网卡在拓扑图上处于同等地位，虚拟机就像是一台真实主机一样存在于局域网中。</p>

<p>桥接模式无法与DHCP一起使用，需要手动的配置虚拟机的网络参数，包括IP、网关、子网掩码和dns。其中网关、子网掩码、dns都应该与host设置相同值。在linux虚拟机中的设置示例如下：</p>

<p>```</p>

<h1>设置ip、子网掩码</h1>

<p>$ifconfig eth0 172.21.2.43 netmask 255.255.0.0</p>

<h1>设置默认网关</h1>

<p>$route add default gw 172.21.1.1</p>

<h1>设置dns</h1>

<p>$sudo vim /etc/resolv.conf
nameserver 172.21.1.1</p>

<p>```</p>

<p>实现原理如图：</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/network/1.jpg"></p>

<p>相比NAT，桥接模式有一个前提条件，就是要获得另外一个host所在网段的IP。在内网环境中还很容易，如果是ADSL宽带就比较麻烦了，ISP一般是不会大方的多提供一个公网IP的，那种情况下，使用NAT或许是更好的选择。</p>

<p><a href="http://blog.chinaunix.net/uid-26212859-id-3051291.html">VMware的桥接网络配置</a></p>

<h3>Host-only networking(主机)</h3>

<p>以host为网关建立了新的虚拟网络，虚拟机无法访问外部网络，因此很安全。</p>

<p>和NAT一样，也使用了DHCP服务做虚拟网络内的IP自动分配。</p>

<p>另外，host-only模式下也可以进行扩展配置，让虚拟网络的机器也能访问到外网，比如自定制nat和dhcp的使用等等。</p>

<p>如图：</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/network/3.jpg"></p>

<h2>参考资料</h2>

<ul>
<li><p><a href="http://networking.ctocio.com.cn/tips/110/8897610.shtml">解析虚拟VMware三种网络模式根本区别</a></p></li>
<li><p><a href="http://www.virtualbox.org/manual/ch06.html">virtualbox的网络模式详解</a></p></li>
</ul>


<p>图片引用自 ：<a href="http://networking.ctocio.com.cn/tips/110/8897610.shtml">解析虚拟VMware三种网络模式根本区别</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[根据前中后序和层序重建二叉树(PAT1020、PAT1043)]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/04/27/pat1020-pat1043-rebuild-binary-tree/"/>
    <updated>2013-04-27T22:33:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/04/27/pat1020-pat1043-rebuild-binary-tree</id>
    <content type="html"><![CDATA[<h2>背景</h2>

<p><a href="/blog/2013/04/27/travsal-binary-tree/">《二叉树的遍历（递归、非递归）分析》</a>总结了二叉树不同遍历方式的递归和非递归实现，本文则讨论如何针对不同遍历方式的组合重建二叉树。为了简化问题的考虑，假定二叉树中不会出现重复值。列入考虑范围的有前序、中序、后序、层序遍历这四种的组合。前中后序比较常见，而层序则相对特殊一点了。</p>

<p><a href="http://pat.zju.edu.cn/contests/pat-a-practise">PAT</a>的1043和1020题是遍历相关的模板题，正好派上用场。</p>

<!--more-->


<h2>中序+前序</h2>

<h5>算法描述：</h5>

<ul>
<li><p>初始：用前序遍历序列确定根节点，在中序遍历序列中找到该根节点，则左右子树分别为中序中该节点左右的序列。</p></li>
<li><p>迭代：对各个子树分别执行三步操作，1.在前序序列中找子树的根节点；2。在中序序列中找子树的根节点，并划分开根节点的左右子树；3.根据新生成的左右子树，在前序序列中划分开这些节点，从而得到了两颗子树的前序、中序序列。</p></li>
</ul>


<h5>练习：<a href="http://pat.zju.edu.cn/contests/pat-a-practise/1043">PAT1043:Is It a Binary Search Tree</a></h5>

<h5>题意：</h5>

<p>输入一个树的前序遍历序列，判定这个树是否是二叉搜索树或者BST的镜像树，如果是，则用后序序列输出。</p>

<h5>解题思路：</h5>

<ul>
<li><p>1.BST很特殊，实质上BST的所有节点的顺序排列就是中序遍历了。</p></li>
<li><p>2.要检查树是否是BST或者镜像BST，只需按照重建树的思路，在每次重建的过程中做适当检查即可。检查思路是：检查前序遍历序列中，根节点之后的节点排序是否符合BST的二分规则（即前一段都是小于根节点的，后一段都是大于根节点的）。</p></li>
<li><p>3.最后的输出是后序遍历。过程中其实并不用构建整个树，直接在处理过程中，按后序的方式存储节点到队列中即可。</p></li>
</ul>


<p>有了这些考虑，就可以写出代码啦。详细解题代码见链接<a href="https://github.com/biaobiaoqi/biaobiaoqiCode/blob/master/src/biaobiaoqi/pat/advancedlevel/APAT1043.java">PAT1043</a></p>

<h2>中序+后序</h2>

<h5>算法描述：</h5>

<ul>
<li><p>初始：用后序遍历序列确定根节点，在中序遍历序列中找到该根节点，则左右子树分别为中序中该节点左右的序列。</p></li>
<li><p>迭代：对各个子树分别执行三步操作，1.在后序序列中找子树的根节点；2。在中序序列中找子树的根节点，并划分开根节点的左右子树；3.根据新生成的左右子树，在后序序列中划分开这些节点，从而得到了两颗子树的后序、中序序列。</p></li>
</ul>


<h5>练习：<a href="http://pat.zju.edu.cn/contests/pat-a-practise/1020">PAT1020:Tree Traversals</a></h5>

<h5>题意：</h5>

<p>输入为一棵二叉树的后序遍历序列和中序遍历序列。求树的前序遍历序列。</p>

<h5>解题思路：</h5>

<ul>
<li><p>1.有了中序和后序，就能重建树。</p></li>
<li><p>2.最后的输出是前序遍历。过程中其实并不用构建整个树。直接在处理过程中，按前序的方式存储节点到队列中即可。</p></li>
</ul>


<p>详细解题代码见链接<a href="https://github.com/biaobiaoqi/biaobiaoqiCode/blob/master/src/biaobiaoqi/pat/advancedlevel/APAT1020.java">PAT1020</a></p>

<h2>中序+层序</h2>

<h5>算法描述：</h5>

<ul>
<li><p>初始：用层序遍历确定顶节点，在中序遍历中，利用顶节点划分出左右子树。</p></li>
<li><p>迭代：对各个子树分别执行三步操作，1.在层序序列中，找出子树节点集合中，最靠前的节点，这个节点即为子树的顶节点；2.在中序序列中找1中得到的顶节点，并划分开顶节点的左右子树；</p></li>
<li><p>跟（中序+前序）和（中序+后序）不同之处在于没有迭代的第3步，层序是无法直接划分得到左右子树的节点集合的。但这并不妨碍正常的处理。层序是用来找到子树的顶节点的，而顶节点即是所有子树的节点中，在层序遍历中最靠前的节点。</p></li>
</ul>


<h2><del>前序+后序</del></h2>

<p>这个组合是<strong>无法</strong>重建确定的二叉树的。</p>

<p>对于满二叉树，利用子树节点的排列顺序能区分开左右子树节点集合，构建是没有问题的。但一旦有单个叶子的节点存在，则无法确定叶子是左儿子还是右儿子。因为无论是前序还是后序序列，都无法体现单个儿子情况下，儿子的位置。前序会将左右子树的点置于节点之后，后序则是将左右子树的点置于节点之前。</p>

<ul>
<li>举个简单的反例：</li>
</ul>


<blockquote><p>给出如下的前序序列和后序序列：
preorder: A, B;
postorder: B, A</p>

<p>能构建的二叉树有两种可能，1.A是根节点，B是A左儿子； 2.A是根节点， B是A的右儿子。无法得到一个唯一的结果。</p></blockquote>

<h2><del>前序+层序</del></h2>

<p>这个组合也是无法重建确定的二叉树的。同样于后序+层序的情况。</p>

<p>道理跟（前序+后序）的道理一样，无论是前序、后序，还是层序，都是无法确定单个儿子节点情况下儿子节点的顺序。</p>

<h2>总结</h2>

<ul>
<li>中序遍历配合另外任何一个遍历，能重建二叉树。其他的任意两个序列的组合都不能唯一的确定重建的二叉树。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[二叉树的遍历（递归、非递归）分析]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/04/27/travsal-binary-tree/"/>
    <updated>2013-04-27T21:03:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/04/27/travsal-binary-tree</id>
    <content type="html"><![CDATA[<h2>背景</h2>

<p>二叉树是一种很基本的数据结构。很多地方能看到它的身影，比如大名鼎鼎的霍夫曼编码（好了，别问我再比如了，见识浅薄，真不知道更多了。。。）它的结构很简洁、巧妙。</p>

<p>本文讨论二叉树的常见遍历方式的代码实现（这里贴出的是Java），包括前序(preorder)、中序(inorder)、后序(postorder)、层序(level order)，进一步，考虑递归和非递归的实现方式。递归方法的实现相对简单，但递归的执行方式由于每次都会产生一个新的方法调用栈，如果递归层级较深，会消耗较大的内存，转化为非递归则没那么简单了，往往需要实现一个栈来保存状态信息。</p>

<!--more-->


<p>在此之前，先简单定义节点的数据结构：</p>

<p>二叉树节点最多只有两个儿子，并保存一个节点的值，为了实验的方便，假定它为int。同时，我们直接使用Java的System.out.print方法来输出节点值，以显示遍历结果。</p>

<p>```
public class Node {</p>

<pre><code>    public int value;
    public Node leftNode;
    public Node rightNode;

    public Node(int i) {
        value = i;
    }
}
</code></pre>

<p>```
详细代码参见链接:<a href="https://github.com/biaobiaoqi/biaobiaoqiCode/blob/master/src/biaobiaoqi/algorithm/tree/BinarySearchTree.java">BST及其各种便利的详细实现代码</a></p>

<h2>前序遍历</h2>

<ul>
<li>递归实现：递归实现很简单，在每次访问到某个节点时，先输出节点值，然后再依次递归的对左儿子、右儿子调用遍历的方法。代码如下</li>
</ul>


<p>```</p>

<pre><code>public void preOrderTrav(Node n) {
    if (n != null) {
        System.out.print(n.value + " ");
        preOrderTrav(n.leftNode);
        preOrderTrav(n.rightNode);
    }
}
</code></pre>

<p>```</p>

<ul>
<li>非递归调实现：</li>
</ul>


<p>1.第一种实现方式相对容易理解：</p>

<p>初始：维护一个栈，将根节点压入栈中。</p>

<p>循环：每次从栈顶读出一个节点信息，直接将节点值<strong>输出</strong>，同时将儿子节点按从左到右的顺序推到栈顶。</p>

<p>分析：跟递归调用的整体思路一样，不同的是，递归调用时是利用运行时系统所维护的程序调用栈来维护顺序，而这个非递归方法是用过自己维护的栈来保存信息。如此节省了调用栈的空间。</p>

<p>```</p>

<pre><code>public void preOrderTravNoRecur(Node n) {
    Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;();
    stack.add(root);
    while (!stack.empty()) {
        Node t = stack.pop();
        System.out.print(t.value + " ");
        if (t.rightNode != null)
            stack.add(t.rightNode);
        if (t.leftNode != null)
            stack.add(t.leftNode);
    }
}
</code></pre>

<p>```</p>

<p>2.第二种实现方式更普遍（中序遍历的非递归使用了同样的思路）：</p>

<p>初始：维护一个栈S和一个节点变量N。节点变量赋值为根节点。</p>

<p>循环：将节点变量N的左儿子循环的<strong>输出</strong>，并推入栈S中，直到没有左儿子；推出栈S的顶节点，节点变量N赋值为栈S顶节点的右节点。</p>

<p>分析：不同于递归调用的思路。栈S用于实现对某节点的左边支递归值的存储，以便回溯；节点变量N则用于遍历某节点的右边枝（这些节点是从栈S顶读出的节点，依次做处理），由于右边枝是最后才会被访问到的，故在处理右边枝的时候，不需要存储右边枝的信息，依次处理即可。</p>

<p>```</p>

<pre><code>public void preOrderTravNoRecurII(Node n) {
    System.out.println("No Recursive: ");
    Stack&lt;Node&gt; s = new Stack&lt;Node&gt;();
    while (n != null | !s.empty()){
        while (n!=null ){
            System.out.print(n.value + " ");
            s.add(n);
            n = n.leftNode;
        }
        n = s.pop();
        n = n.rightNode;
    }
    System.out.println();
}
</code></pre>

<p>```</p>

<h3>中序遍历</h3>

<ul>
<li>递归实现</li>
</ul>


<p>```</p>

<pre><code>public void inorderTrav(Node n) {
    if (n != null) {
        inorderTrav(n.leftNode);
        System.out.print(n.value + " ");
        inorderTrav(n.rightNode);
    }
}
</code></pre>

<p>```</p>

<ul>
<li>非递归实现</li>
</ul>


<p>初始：维护一个栈S和一个节点变量N。节点变量赋值为根节点。</p>

<p>循环：将节点变量N的左儿子循环的<strong>输出</strong>，并推入栈S中，直到没有左儿子；节点变量N赋值为栈S顶节点的右节点。</p>

<p>分析：跟前序遍历的非递归实现方法二很类似。唯一的不同是输出的时机不同：前序遍历在入栈时输出，而中序遍历在出栈时输出。可以跟深刻的理解到，栈在这里是为了回溯而存在的。</p>

<p>```</p>

<pre><code>public void inorderTravNoRecu(Node n) {
    System.out.println("No Recursive: ");
    Stack&lt;Node&gt; s = new Stack&lt;Node&gt;();
    while (n != null | !s.empty()){
        while (n!=null ){
            s.add(n);
            n = n.leftNode;
        }
        n = s.pop();
        System.out.print(n.value + " ");
        n = n.rightNode;
    }
}
</code></pre>

<p>```</p>

<h3>后序遍历</h3>

<ul>
<li>递归实现</li>
</ul>


<p>```
public void preOrderTravNoRecurII(Node n) {</p>

<pre><code>    System.out.println("No Recursive: ");
    Stack&lt;Node&gt; s = new Stack&lt;Node&gt;();
    while (n != null | !s.empty()){
        while (n!=null ){
            System.out.print(n.value + " ");
            s.add(n);
            n = n.leftNode;
        }
        n = s.pop();

        n = n.rightNode;
    }
    System.out.println();
}
</code></pre>

<p>```</p>

<ul>
<li>非递归实现</li>
</ul>


<p>初始：1.维护一个栈S、一个节点变量N和一个标记数组。节点变量赋值为根节点，栈暂时存储便利到的节点，标记数组用于标记栈中的节点是否已经访问过右边节点。2.将根节点的所有左儿子压入栈中。</p>

<p>循环：依次处理栈中节点。如果节点有右儿子，且没有被处理过（通过标记数组判定），则将右子树的根节点及其左儿子全部压入栈中；如果已经处理过或者没有右儿子，则输出并出栈。</p>

<p>分析：与前序和中序的一个大的不同在于需要用标记数组标记节点的右子树是否已经访问过。对每个节点进行处理的时候，都保证已经处理完了左右子树（通过先压入左边儿子为主线，处理栈中的每个节点时，再压入右边儿子来实现）。</p>

<p>```
public void postOrderTravNoRecu(Node n) {</p>

<pre><code>    Stack&lt;Node&gt; stack = new Stack&lt;Node&gt;();
    int[] flag = new int[max];

    while (n != null) {
        stack.push(n);
        flag[stack.size()] = 0;
        n = n.leftNode;
    }

    while (!stack.empty()) {
        n = stack.peek();
        while(n.rightNode != null &amp;&amp; flag[stack.size()] == 0) {
            n = n.rightNode;
            flag[stack.size()] = 1;
            while (n != null) {
                stack.push(n);
                flag[stack.size()] = 0;
                n = n.leftNode;
            }
            n = stack.peek();//TODO be careful about this
        }
        n = stack.pop();
        System.out.print(n.value + " ");
    }

}
</code></pre>

<p>```</p>

<h3>层序遍历</h3>

<ul>
<li>无法使用递归方法</li>
</ul>


<p>层序遍历不同于其他的遍历。可以通过反证法证明：</p>

<p>如果能实现对A节点的层序递归，在对A节点处理的过程中，应该递归的对两个儿子B和C分别调用了层序遍历。在这种情况下，我们无法让B和C的同一个层级的儿子在集中的时间中被遍历到，换言之，B的第一层儿子在对B的调用中被遍历，而C的第一层儿子，则在对C的调用中遍历，这是分离开的。不成立，得证。</p>

<ul>
<li>非递归方法：</li>
</ul>


<p>分析：此方法类似于前序遍历的非递归方法的第一种。用一个栈维护信息。</p>

<p>```</p>

<pre><code>public void levelOrderTrav(Node n) {
    System.out.print("Level OrderTrav: ");

    Queue&lt;Node&gt; q = new LinkedList&lt;Node&gt;();
    q.add(n);
    while (q.size() != 0) {
        n = q.poll();
        System.out.print(" " + n.value);
        if (n.leftNode != null) 
            q.add(n.leftNode);
        if (n.rightNode != null)
            q.add(n.rightNode);

    }
}
</code></pre>

<p>```</p>

<h2>总结</h2>

<p>非递归实现的代码相对来说没有递归实现的直观。其核心都是维护了一个栈来保存状态，避免了产生过多方法调用栈浪费内存空间。</p>

<p>本文中针对二叉树的几种遍历方式，描述了递归和非递归的解决方案。普遍意义的递归转非递归的方法和思想，将在另外一篇博文中介绍;)。欢迎交流。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PDW中的Split Querying Process]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/04/25/split-querying-process-in-polybase/"/>
    <updated>2013-04-25T22:59:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/04/25/split-querying-process-in-polybase</id>
    <content type="html"><![CDATA[<p>最近看了关于SQL Server的分布式处理方面的论文，觉得它提出的Polybase跟之前看过的HadoopDB有些神似，这里做个小总结（抽空再把HadoopDB的总结贴出来）。</p>

<p>不算翻译，只是挑出自己认为是重点的部分。详细情况，还请论文查阅原文，引用中有写明出处。文章末尾有我总结的slides，可以辅助查阅。</p>

<p>由于缺乏实践经验，很多东西未必能理解其本质。如有其他观点，还请多指教。</p>

<p>当下的计划就是开始自己搭环境，实践起来!~</p>

<!--more-->


<h2>背景</h2>

<p>商业应用中，越来越多的需要将结构化数据和非结构化数据存储、处理混合起来。
目前，已经有很多公司、产品致力于这部分的研究，微软发的这篇论文，也正是基于PDW V2的这一新功能提出的新的解决方案。</p>

<h3>Polybase简介：</h3>

<p>是SQL Server PDW V2的一个新功能：通过使用SQL来管理和查询hadoop集群中的数据。
它同时能处理结构化和非结构化的数据，特点是结合了HDFS的外部表，使用基于开销的查询优化器来做分裂查询处理。</p>

<h2>相关研究</h2>

<ul>
<li><p>sqoop：用于在hadoop和结构化数据9比如关系型数据库之间传输数据。</p></li>
<li><p>teradata&amp; Asterdata&amp; Greenplum&amp; Vertica：通过外部表（external table）实现基于SQL的对hadoop中所存数据的操作。</p></li>
<li><p>Orable：基本机制也是建立外部表；另外还开发了用于加载hadoop的大数据到Oracle自家数据库的工具OLH(Oracle loader for Hadoop)。</p></li>
<li><p>IBM、Netezza:使用mapreduce方法获取分布式环境下各个节点的数据执行处理。</p></li>
<li><p>Hadapt: (HadoopDB)：HadoopDB是来自耶鲁大学的创意，并商业化为Hadapt项目。这是首个提出使用类SQL语言、集合Hadoop系统实现对RDBMS的操作的想法。实现相对简单，源代码3千多行，在Hadoop中对其中的几个模块做了二次开发。</p></li>
</ul>


<h2>PDW</h2>

<p>Polybase是PDW V2的一个新feature，那么，首先，让我们来看一下所谓的PDW是什么。</p>

<p>PDW是一个基于SQL Server的shared-nothing的并行数据库系统。</p>

<p>PDW（Parallel Data Warehouse）架构图：</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image0.png"></p>

<h3>PDW系统中的组件：</h3>

<h5>节点</h5>

<ul>
<li>control node：</li>
</ul>


<p>类似于Hadoop中的master节点。运行着PDW Engine，负责：查询语法分析，优化，生成分布式执行计划DSQL，控制计划实施</p>

<ul>
<li>compute node：</li>
</ul>


<p>类似于Hadoop中的slave节点。数据存储和查询执行</p>

<h4>DMS</h4>

<p>Data Moving Service，起功能有：</p>

<ul>
<li><p>1.repartition rows of a table among SQL Server instances on PDW compute nodes</p></li>
<li><p>2.针对ODBC的类型转换。</p></li>
</ul>


<h2>Polybase</h2>

<h3>Polybase使用场景</h3>

<p>如图</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image1.png"></p>

<p>（a）中PDW与Hadoop一起完成了数据处理任务，并输出结果；</p>

<p>（b）中处理数据后，结果直接存储到HDFS中</p>

<p>充分利用SQL Server PDW的性能优势，特别是它的基于开销的并行查询优化器和执行引擎。</p>

<h3>Polybase的环境需求</h3>

<ul>
<li>1.PDW与Hadoop集群可以重叠，也可以分离。</li>
<li>2.windows 和 linux部署的hadoop集群都支持。</li>
<li>3.支持所有标准的HDFS文件格式，包括文本、序列化文件、RCFiles。只要定义好对应的Inputformat和outputFormat，所有定制文件格式也支持。</li>
</ul>


<h3>核心组件</h3>

<ul>
<li>1.外部表：用于在PDW中实现对数据的操作语义。</li>
<li>2.HDFS Bridge：DMS中的组件，用于实现PDW节点域Hadoop的通信。</li>
<li>3.基于开销的查询优化器：将常规SQL查询语句转化为DSQL（分布式SQL查询语句），并结合集群状况（比如Hadoop和PDW集群规模，运行状况等），合理选择优化方式。</li>
</ul>


<h3>1.外部表</h3>

<p>PDW需要了解到Hadoop集群中数据的模型。于是就有了这个外部表。
实例如下：</p>

<p>创建集群：</p>

<p>```
CREATE HADOOP_CLUSTER GSL_CLUSTER</p>

<pre><code>  WITH (namenode=‘hadoop-head’,namenode_port=9000,

  jobtracker=‘hadoop-head’,jobtracker_port=9010);
</code></pre>

<p>```</p>

<p>创建文件格式：</p>

<p>```
CREATE HADOOP_FILEFORMAT TEXT_FORMAT</p>

<p>  WITH (INPUT_FORMAT=‘polybase.TextInputFormat’,</p>

<p>  OUTPUT_FORMAT = ‘polybase.TextOutputFormat’,</p>

<p>  ROW_DELIMITER = '\n', COLUMN_DELIMITER = ‘|’);</p>

<p>```</p>

<p>根据集群和文件信息，创建外部表
```
CREATE EXTERNAL TABLE hdfsCustomer</p>

<p>  ( c_custkey       bigint not null,</p>

<pre><code>c_name          varchar(25) not null,

 .......
)
</code></pre>

<p>WITH (LOCATION='/tpch1gb/customer.tbl',</p>

<p>FORMAT_OPTIONS (EXTERNAL_CLUSTER = GSL_CLUSTER,</p>

<p>EXTERNAL_FILEFORMAT = TEXT_FORMAT));
```</p>

<h3>2.HDFS Bridge</h3>

<p>结构如图：
<img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image2.png"></p>

<p>HDFS shuffle阶段：通过DMS从hadoop读取数据的阶段。
涉及到hdfs中的数据处理时，处理过程如下：</p>

<ul>
<li><p>1.跟namenode通信，获得hdfs中文件的信息</p></li>
<li><p>2.hdfs中文件信息 +  DMS实例个数 -> 每个DMS的输入文件（offset、长度） #力求负载均衡</p></li>
<li><p>3.将DMS的输入文件信息传递给各个DMS，DMS通过 openRecordReader（）方法构建RecordReader实例，直接与对应的datanode通信，获取数据，并转换为ODBC格式（有时候类型转换提前到mapreduce中以利用hadoop集群的计算能力）。读取过程中，使用了buffer机制提高效率。有时候数据会被提前到从HDFS中读出时执行，而不是到DMS中执行。这是为了充分利用hadoop集群的计算能力，节约CPU秘籍的DMS shuffle的计算。</p></li>
</ul>


<p>写入hadoop的过程与此类似。</p>

<h3>3.查询优化</h3>

<ul>
<li><p>1.PDW Parser(在PDW Engine的进程中完成)。</p></li>
<li><p>2.SQL Server Query Optimizer(在control node的SQL Server的进程中完成)：使用bottom-up的方式进行查询优化，并在合理的位置插入数据迁移的操作符（用于分布式环境的数据迁移指令），:生成查询计划，存储在Memo数据结构（http://www.benjaminnevarez.com/2012/04/inside-the-query-optimizer-memo-structure/）中 。</p></li>
<li><p>3.XML geneator(在control node的SQL Server的进程中完成)。接收Memo，并转换格式，往下传递。</p></li>
<li><p>4.Query Optimizer(在PDW Engine的进程中完成)：根据Memo生成DSQL。</p></li>
<li><p>5.基于开销的查询优化：判定是否将SQL语句推送到Hadoop中执行。</p>

<p>  考虑外部表的样本数据的直方图、集群的规模等因素...选择最优优化方案。</p></li>
</ul>


<h5>样本数据处理:</h5>

<p>定义对应外部表列的详细样本数据：</p>

<p><code>
CREATE STATISTICS hdfsCustomerStats ON
hdfsCustomer (c_custkey);
</code></p>

<p>对样本数据的处理的方式如下：</p>

<ul>
<li>1.通过DMS或者map job读取sample数据，</li>
<li>2.分发到不同的comute节点的暂存表。</li>
<li>3.每个节点分别计算直方图。</li>
<li>4.汇总直方图，存储到control node数据库的catalog中</li>
</ul>


<p>缺点是在此过程中没有利用好hadoop集群的计算能力。</p>

<h3>语义兼容</h3>

<p>涉及到Java和SQL以及之间的转换。包括这三个方面：</p>

<ul>
<li>数据类型的语义.</li>
<li>表达式的语义</li>
<li>异常处理机制</li>
</ul>


<p>例如："a+b"，其中a，b都为null，SQL结果为NULL，而Java则会抛出NullException。</p>

<p>处理原则是：能转化的类型则做好转化包装；不能转换的则标记为无法实现，仅限PDW实现。</p>

<h3>举例：</h3>

<p><code>
   SELECT count (*) from Customer
  WHERE acctbal &lt; 0
  GROUP BY nationkey
</code></p>

<p>如图所示为处理过程</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image4.png"></p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image5.png"></p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image6.png"></p>

<h3>Polybase的MapReduce Join实现</h3>

<p>使用distributed hash join实现（只有equi-join能被在mapreduce中完成）</p>

<p>小表作为build side ，并被物化（materialized）到HDFS，大表作为probe side。</p>

<p>在Hadoop的Map任务中：读取物化好的build side到内存，构成hash table。</p>

<p>probe side经过hash后对比hash表，做正确的链接。</p>

<p>为了让build side置于内存中，需要计算build side的大小、每个task拥有的内存大小，task中执行其他操作需要的内存空间。
当然，build side也可能被复制多分，以提高效率。</p>

<p><a href="http://dl.dropboxusercontent.com/u/64021093/pdw/Split%20Query%20Processing%20in%20Polybase.pptx">本文演示slides下载链接，点击获取</a></p>

<h2>引用</h2>

<ul>
<li>Split Query Processing in Polybase(SIGMOD’13， June 22-27,2013,New York,USA.) Microsoft Corporation</li>
<li>Polybase:  What, Why, How(ppt) Microsoft Corporation</li>
<li>Query Optimization in Microsoft SQL Server PDW(SIGMOD'12, May 20-24,2012,Scottsdale,Arizona,USA) Microsoft Corporation</li>
</ul>

]]></content>
  </entry>
  
</feed>
