<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: distributed | Biaobiaoqi的博客]]></title>
  <link href="http://biaobiaoqi.github.com/blog/categories/distributed/atom.xml" rel="self"/>
  <link href="http://biaobiaoqi.github.com/"/>
  <updated>2013-05-06T00:25:41+08:00</updated>
  <id>http://biaobiaoqi.github.com/</id>
  <author>
    <name><![CDATA[Biaobiaoqi]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[PDW中的Split Querying Process]]></title>
    <link href="http://biaobiaoqi.github.com/blog/2013/04/25/split-querying-process-in-polybase/"/>
    <updated>2013-04-25T22:59:00+08:00</updated>
    <id>http://biaobiaoqi.github.com/blog/2013/04/25/split-querying-process-in-polybase</id>
    <content type="html"><![CDATA[<p>最近看了关于SQL Server的分布式处理方面的论文，觉得它提出的Polybase跟之前看过的HadoopDB有些神似，这里做个小总结（抽空再把HadoopDB的总结贴出来）。</p>

<p>不算翻译，只是挑出自己认为是重点的部分。详细情况，还请论文查阅原文，引用中有写明出处。文章末尾有我总结的slides，可以辅助查阅。</p>

<p>由于缺乏实践经验，很多东西未必能理解其本质。如有其他观点，还请多指教。</p>

<p>当下的计划就是开始自己搭环境，实践起来!~</p>

<h2>背景</h2>

<p>商业应用中，越来越多的需要将结构化数据和非结构化数据存储、处理混合起来。
目前，已经有很多公司、产品致力于这部分的研究，微软发的这篇论文，也正是基于PDW V2的这一新功能提出的新的解决方案。</p>

<!--more-->


<h3>Polybase简介：</h3>

<p>是SQL Server PDW V2的一个新功能：通过使用SQL来管理和查询hadoop集群中的数据。
它同时能处理结构化和非结构化的数据，特点是结合了HDFS的外部表，使用基于开销的查询优化器来做分裂查询处理。</p>

<h2>相关研究</h2>

<ul>
<li><p>sqoop：用于在hadoop和结构化数据9比如关系型数据库之间传输数据。</p></li>
<li><p>teradata&amp; Asterdata&amp; Greenplum&amp; Vertica：通过外部表（external table）实现基于SQL的对hadoop中所存数据的操作。</p></li>
<li><p>Orable：基本机制也是建立外部表；另外还开发了用于加载hadoop的大数据到Oracle自家数据库的工具OLH(Oracle loader for Hadoop)。</p></li>
<li><p>IBM、Netezza:使用mapreduce方法获取分布式环境下各个节点的数据执行处理。</p></li>
<li><p>Hadapt: (HadoopDB)：HadoopDB是来自耶鲁大学的创意，并商业化为Hadapt项目。这是首个提出使用类SQL语言、集合Hadoop系统实现对RDBMS的操作的想法。实现相对简单，源代码3千多行，在Hadoop中对其中的几个模块做了二次开发。</p></li>
</ul>


<h2>PDW</h2>

<p>Polybase是PDW V2的一个新feature，那么，首先，让我们来看一下所谓的PDW是什么。</p>

<p>PDW是一个基于SQL Server的shared-nothing的并行数据库系统。</p>

<p>PDW（Parallel Data Warehouse）架构图：</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image0.png"></p>

<h3>PDW系统中的组件：</h3>

<h5>节点</h5>

<ul>
<li>control node：</li>
</ul>


<p>类似于Hadoop中的master节点。运行着PDW Engine，负责：查询语法分析，优化，生成分布式执行计划DSQL，控制计划实施</p>

<ul>
<li>compute node：</li>
</ul>


<p>类似于Hadoop中的slave节点。数据存储和查询执行</p>

<h4>DMS</h4>

<p>Data Moving Service，起功能有：</p>

<ul>
<li><p>1.repartition rows of a table among SQL Server instances on PDW compute nodes</p></li>
<li><p>2.针对ODBC的类型转换。</p></li>
</ul>


<h2>Polybase</h2>

<h3>Polybase使用场景</h3>

<p>如图</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image1.png"></p>

<p>（a）中PDW与Hadoop一起完成了数据处理任务，并输出结果；</p>

<p>（b）中处理数据后，结果直接存储到HDFS中</p>

<p>充分利用SQL Server PDW的性能优势，特别是它的基于开销的并行查询优化器和执行引擎。</p>

<h3>Polybase的环境需求</h3>

<ul>
<li>1.PDW与Hadoop集群可以重叠，也可以分离。</li>
<li>2.windows 和 linux部署的hadoop集群都支持。</li>
<li>3.支持所有标准的HDFS文件格式，包括文本、序列化文件、RCFiles。只要定义好对应的Inputformat和outputFormat，所有定制文件格式也支持。</li>
</ul>


<h3>核心组件</h3>

<ul>
<li>1.外部表：用于在PDW中实现对数据的操作语义。</li>
<li>2.HDFS Bridge：DMS中的组件，用于实现PDW节点域Hadoop的通信。</li>
<li>3.基于开销的查询优化器：将常规SQL查询语句转化为DSQL（分布式SQL查询语句），并结合集群状况（比如Hadoop和PDW集群规模，运行状况等），合理选择优化方式。</li>
</ul>


<h3>1.外部表</h3>

<p>PDW需要了解到Hadoop集群中数据的模型。于是就有了这个外部表。
实例如下：</p>

<p>创建集群：</p>

<p>```
CREATE HADOOP_CLUSTER GSL_CLUSTER</p>

<pre><code>  WITH (namenode=‘hadoop-head’,namenode_port=9000,

  jobtracker=‘hadoop-head’,jobtracker_port=9010);
</code></pre>

<p>```</p>

<p>创建文件格式：</p>

<p>```
CREATE HADOOP_FILEFORMAT TEXT_FORMAT</p>

<p>  WITH (INPUT_FORMAT=‘polybase.TextInputFormat’,</p>

<p>  OUTPUT_FORMAT = ‘polybase.TextOutputFormat’,</p>

<p>  ROW_DELIMITER = '\n', COLUMN_DELIMITER = ‘|’);</p>

<p>```</p>

<p>根据集群和文件信息，创建外部表
```
CREATE EXTERNAL TABLE hdfsCustomer</p>

<p>  ( c_custkey       bigint not null,</p>

<pre><code>c_name          varchar(25) not null,

 .......
)
</code></pre>

<p>WITH (LOCATION='/tpch1gb/customer.tbl',</p>

<p>FORMAT_OPTIONS (EXTERNAL_CLUSTER = GSL_CLUSTER,</p>

<p>EXTERNAL_FILEFORMAT = TEXT_FORMAT));
```</p>

<h3>2.HDFS Bridge</h3>

<p>结构如图：
<img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image2.png"></p>

<p>HDFS shuffle阶段：通过DMS从hadoop读取数据的阶段。
涉及到hdfs中的数据处理时，处理过程如下：</p>

<ul>
<li><p>1.跟namenode通信，获得hdfs中文件的信息</p></li>
<li><p>2.hdfs中文件信息 +  DMS实例个数 -> 每个DMS的输入文件（offset、长度） #力求负载均衡</p></li>
<li><p>3.将DMS的输入文件信息传递给各个DMS，DMS通过 openRecordReader（）方法构建RecordReader实例，直接与对应的datanode通信，获取数据，并转换为ODBC格式（有时候类型转换提前到mapreduce中以利用hadoop集群的计算能力）。读取过程中，使用了buffer机制提高效率。有时候数据会被提前到从HDFS中读出时执行，而不是到DMS中执行。这是为了充分利用hadoop集群的计算能力，节约CPU秘籍的DMS shuffle的计算。</p></li>
</ul>


<p>写入hadoop的过程与此类似。</p>

<h3>3.查询优化</h3>

<ul>
<li><p>1.PDW Parser(在PDW Engine的进程中完成)。</p></li>
<li><p>2.SQL Server Query Optimizer(在control node的SQL Server的进程中完成)：使用bottom-up的方式进行查询优化，并在合理的位置插入数据迁移的操作符（用于分布式环境的数据迁移指令），:生成查询计划，存储在Memo数据结构（http://www.benjaminnevarez.com/2012/04/inside-the-query-optimizer-memo-structure/）中 。</p></li>
<li><p>3.XML geneator(在control node的SQL Server的进程中完成)。接收Memo，并转换格式，往下传递。</p></li>
<li><p>4.Query Optimizer(在PDW Engine的进程中完成)：根据Memo生成DSQL。</p></li>
<li><p>5.基于开销的查询优化：判定是否将SQL语句推送到Hadoop中执行。</p>

<p>  考虑外部表的样本数据的直方图、集群的规模等因素...选择最优优化方案。</p></li>
</ul>


<h5>样本数据处理:</h5>

<p>定义对应外部表列的详细样本数据：</p>

<p><code>
CREATE STATISTICS hdfsCustomerStats ON
hdfsCustomer (c_custkey);
</code></p>

<p>对样本数据的处理的方式如下：</p>

<ul>
<li>1.通过DMS或者map job读取sample数据，</li>
<li>2.分发到不同的comute节点的暂存表。</li>
<li>3.每个节点分别计算直方图。</li>
<li>4.汇总直方图，存储到control node数据库的catalog中</li>
</ul>


<p>缺点是在此过程中没有利用好hadoop集群的计算能力。</p>

<h3>语义兼容</h3>

<p>涉及到Java和SQL以及之间的转换。包括这三个方面：</p>

<ul>
<li>数据类型的语义.</li>
<li>表达式的语义</li>
<li>异常处理机制</li>
</ul>


<p>例如："a+b"，其中a，b都为null，SQL结果为NULL，而Java则会抛出NullException。</p>

<p>处理原则是：能转化的类型则做好转化包装；不能转换的则标记为无法实现，仅限PDW实现。</p>

<h3>举例：</h3>

<p><code>
   SELECT count (*) from Customer
  WHERE acctbal &lt; 0
  GROUP BY nationkey
</code></p>

<p>如图所示为处理过程</p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image4.png"></p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image5.png"></p>

<p><img src="http://dl.dropboxusercontent.com/u/64021093/pdw/Image6.png"></p>

<h3>Polybase的MapReduce Join实现</h3>

<p>使用distributed hash join实现（只有equi-join能被在mapreduce中完成）</p>

<p>小表作为build side ，并被物化（materialized）到HDFS，大表作为probe side。</p>

<p>在Hadoop的Map任务中：读取物化好的build side到内存，构成hash table。</p>

<p>probe side经过hash后对比hash表，做正确的链接。</p>

<p>为了让build side置于内存中，需要计算build side的大小、每个task拥有的内存大小，task中执行其他操作需要的内存空间。
当然，build side也可能被复制多分，以提高效率。</p>

<p><a href="http://dl.dropboxusercontent.com/u/64021093/pdw/Split%20Query%20Processing%20in%20Polybase.pptx">本文演示slides下载链接，点击获取</a></p>

<h2>引用</h2>

<ul>
<li>Split Query Processing in Polybase(SIGMOD’13， June 22-27,2013,New York,USA.) Microsoft Corporation</li>
<li>Polybase:  What, Why, How(ppt) Microsoft Corporation</li>
<li>Query Optimization in Microsoft SQL Server PDW(SIGMOD'12, May 20-24,2012,Scottsdale,Arizona,USA) Microsoft Corporation</li>
</ul>

]]></content>
  </entry>
  
</feed>
